{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7yuytuIllsv1"
   },
   "source": [
    "\n",
    "# Assignment 2: Transformer Summarizer\n",
    "\n",
    "Welcome to the second assignment of course 4. In this assignment you will explore summarization using the transformer model. Yes, you will implement the transformer decoder from scratch, but we will slowly walk you through it. There are many hints in this notebook so feel free to use them as needed. \n",
    "\n",
    "<img src = \"transformerNews.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4-3lxSnXRWPx"
   },
   "source": [
    "## Outline\n",
    "\n",
    "- [Introduction](#0)\n",
    "- [Part 1: Importing the dataset](#1)\n",
    "    - [1.1 Encode & Decode helper functions](#1.1)\n",
    "    - [1.2 Defining parameters](#1.2)\n",
    "    - [1.3 Exploring the data](#1.3)\n",
    "- [Part 2: Summarization with transformer](#2)\n",
    "    - [2.1 Dot product attention](#2.1)\n",
    "        - [Exercise 01](#ex01)\n",
    "    - [2.2 Causal Attention](#2.2)\n",
    "        - [Exercise 02](#ex02)\n",
    "    - [2.3 Transformer decoder block](#2.3)\n",
    "        - [Exercise 03](#ex03)\n",
    "    - [2.4 Transformer Language model](#2.4)\n",
    "        - [Exercise 04](#ex04)\n",
    "- [Part 3: Training](#3)\n",
    "    - [3.1 Training the model](#3.1)\n",
    "        - [Exercise 05](#ex05)\n",
    "- [Part 4: Evaluation](#4)\n",
    "    - [4.1 Loading in a trained model](#4.1)\n",
    "- [Part 5: Testing with your own input](#5) \n",
    "    - [Exercise 6](#ex06)\n",
    "    - [5.1 Greedy decoding](#5.1)\n",
    "        - [Exercise 07](#ex07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H4NlfEQhRWPy"
   },
   "source": [
    "<a name='0'></a>\n",
    "### Introduction\n",
    "\n",
    "Summarization is an important task in natural language processing and could be useful for a consumer enterprise. For example, bots can be used to scrape articles, summarize them, and then you can use sentiment analysis to identify the sentiment about certain stocks. Anyways who wants to read an article or a long email today, when you can build a transformer to summarize text for you. Let's get started, by completing this assignment you will learn to:  \n",
    "\n",
    "- Use built-in functions to preprocess your data\n",
    "- Implement DotProductAttention\n",
    "- Implement Causal Attention\n",
    "- Understand how attention works\n",
    "- Build the transformer model\n",
    "- Evaluate your model\n",
    "- Summarize an article\n",
    "\n",
    "As you can tell, this model is slightly different than the ones you have already implemented. This is heavily based on attention and does not rely on sequences, which allows for parallel computing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CChWzW-rEHVb",
    "outputId": "a0b3e98b-7fc6-492d-c8ad-3a263b54f670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens_length=568 inputs_length=512 targets_length=114 noise_density=0.15 mean_noise_span_length=3.0 \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.fastmath import numpy as jnp\n",
    "\n",
    "# to print the entire np array\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kEL2rvaHRWP4"
   },
   "source": [
    "<a name='1'></a>\n",
    "## Part 1: Importing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trax makes it easy to work with Tensorflow's datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VInmKSkhEhle"
   },
   "outputs": [],
   "source": [
    "# This will download the dataset if no data_dir is specified.\n",
    "# Downloading and processing can take bit of time,\n",
    "# so we have the data already in 'data/' for you\n",
    "\n",
    "# Importing CNN/DailyMail articles dataset\n",
    "train_stream_fn = trax.data.TFDS('cnn_dailymail',\n",
    "                                 data_dir='data/',\n",
    "                                 keys=('article', 'highlights'),\n",
    "                                 train=True)\n",
    "\n",
    "# This should be much faster as the data is downloaded already.\n",
    "eval_stream_fn = trax.data.TFDS('cnn_dailymail',\n",
    "                                data_dir='data/',\n",
    "                                keys=('article', 'highlights'),\n",
    "                                train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "## 1.1 Tokenize & Detokenize helper functions\n",
    "\n",
    "Just like in the previous assignment, the cell above loads in the encoder for you. Given any data set, you have to be able to map words to their indices, and indices to their words. The inputs and outputs to your [Trax](https://github.com/google/trax) models are usually tensors of numbers where each number corresponds to a word. If you were to process your data manually, you would have to make use of the following: \n",
    "\n",
    "- <span style='color:blue'> word2Ind: </span> a dictionary mapping the word to its index.\n",
    "- <span style='color:blue'> ind2Word:</span> a dictionary mapping the index to its word.\n",
    "- <span style='color:blue'> word2Count:</span> a dictionary mapping the word to the number of times it appears. \n",
    "- <span style='color:blue'> num_words:</span> total number of words that have appeared. \n",
    "\n",
    "Since you have already implemented these in previous assignments of the specialization, we will provide you with helper functions that will do this for you. Run the cell below to get the following functions:\n",
    "\n",
    "- <span style='color:blue'> tokenize: </span> converts a text sentence to its corresponding token list (i.e. list of indices). Also converts words to subwords.\n",
    "- <span style='color:blue'> detokenize: </span> converts a token list to its corresponding sentence (i.e. string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djTiSLcaNFGa"
   },
   "outputs": [],
   "source": [
    "def tokenize(input_str, EOS=1):\n",
    "    \"\"\"Input str to features dict, ready for inference\"\"\"\n",
    "  \n",
    "    # Use the trax.data.tokenize method. It takes streams and returns streams,\n",
    "    # we get around it by making a 1-element stream with `iter`.\n",
    "    inputs =  next(trax.data.tokenize(iter([input_str]),\n",
    "                                      vocab_dir='vocab_dir/',\n",
    "                                      vocab_file='summarize32k.subword.subwords'))\n",
    "    \n",
    "    # Mark the end of the sentence with EOS\n",
    "    return list(inputs) + [EOS]\n",
    "\n",
    "def detokenize(integers):\n",
    "    \"\"\"List of ints to str\"\"\"\n",
    "  \n",
    "    s = trax.data.detokenize(integers,\n",
    "                             vocab_dir='vocab_dir/',\n",
    "                             vocab_file='summarize32k.subword.subwords')\n",
    "    \n",
    "    return wrapper.fill(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7WvhaFbCRWQS"
   },
   "source": [
    "<a name='1.2'></a>\n",
    "\n",
    "## 1.2 Preprocessing for Language Models: Concatenate It!\n",
    "\n",
    "This week you will use a language model -- Transformer Decoder -- to solve\n",
    "an input-output problem. As you know, language models only predict the next\n",
    "word, they have no notion of inputs. To create a single input suitable for\n",
    "a language model, we concatenate inputs with targets putting a separator\n",
    "in between. We also need to create a mask -- with 0s at inputs and 1s at targets -- so that the model is not penalized for mis-predicting the article and only focuses on the summary. See the preprocess function below for how this is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4rgPxYSRWQS"
   },
   "outputs": [],
   "source": [
    "# Special tokens\n",
    "SEP = 0 # Padding or separator token\n",
    "EOS = 1 # End of sentence token\n",
    "\n",
    "# Concatenate tokenized inputs and targets using 0 as separator.\n",
    "def preprocess(stream):\n",
    "    for (article, summary) in stream:\n",
    "        joint = np.array(list(article) + [EOS, SEP] + list(summary) + [EOS])\n",
    "        mask = [0] * (len(list(article)) + 2) + [1] * (len(list(summary)) + 1) # Accounting for EOS and SEP\n",
    "        yield joint, joint, np.array(mask)\n",
    "\n",
    "# You can combine a few data preprocessing steps into a pipeline like this.\n",
    "input_pipeline = trax.data.Serial(\n",
    "    # Tokenizes\n",
    "    trax.data.Tokenize(vocab_dir='vocab_dir/',\n",
    "                       vocab_file='summarize32k.subword.subwords'),\n",
    "    # Uses function defined above\n",
    "    preprocess,\n",
    "    # Filters out examples longer than 2048\n",
    "    trax.data.FilterByLength(2048)\n",
    ")\n",
    "\n",
    "# Apply preprocessing to data streams.\n",
    "train_stream = input_pipeline(train_stream_fn())\n",
    "eval_stream = input_pipeline(eval_stream_fn())\n",
    "\n",
    "train_input, train_target, train_mask = next(train_stream)\n",
    "\n",
    "assert sum((train_input - train_target)**2) == 0  # They are the same in Language Model (LM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "uKFoGsUKSa_I",
    "outputId": "bc4d6634-d716-4311-d49c-1956bca2bc2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example mask:\n",
      "\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# prints mask, 0s on article, 1s on summary\n",
    "print(f'Single example mask:\\n\\n {train_mask}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "S4uHyCkbSuUo",
    "outputId": "52845be8-f2fc-4803-bf7a-ed9725fe2bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single example:\n",
      "\n",
      " Standoff: Goerge Pickering, pictured, allegedly threatened to kill a\n",
      "nurse . A distraught father who caused a four-hour standoff with\n",
      "police in a Texas hospital allegedly pointed his gun at a nurse and\n",
      "yelled 'I'll kill all of y'all'. Police said George Pickering, 57,\n",
      "made the threats from a hospital room after becoming inconsolable over\n",
      "the treatment of his son - a patient in critical care at Tomball\n",
      "Regional Hospital, near Houston. Armed police and a SWAT team\n",
      "descended on the medical center - and eventually convinced Pickering\n",
      "to surrender after a four-hour standoff on Saturday night. Pickering\n",
      "was charged with aggravated assault with a deadly weapon and is being\n",
      "held on a $30,000 bond, a statement from the Tomball Police department\n",
      "said. Detectives said Pickering was in the room with his son and\n",
      "family, waited for a nurse to come, then aimed his 9mm pistol at her.\n",
      "He then allegedly barricaded the room and threatened to kill anybody\n",
      "who came in. At the start of the confrontation, another of Pickering's\n",
      "sons, who was with him in the hospital room, allegedly wrested the gun\n",
      "away from him and handed it to police. Standoff: George Pickering, 57,\n",
      "allegedly threatened to kill a nurse with his pistol at Tomball\n",
      "Regional Hospital, sparking a police standoff . Response: Police and a\n",
      "SWAT team arrived at the hospital. Pickering reportedly had one gun\n",
      "taken from him, but said he had a second . Pickering then allegedly\n",
      "said, 'You don't think that's the only weapon I have?', prompting\n",
      "fears of a second gun and causing the lengthy showdown with police.\n",
      "But when he gave himself up, police found that he was not in fact\n",
      "armed. Early reports stated that Pickering had taken two hostages, but\n",
      "law enforcement later said there were no captives. A spokesman for the\n",
      "Tomball police department said Picerking fell ill during the standoff\n",
      "and was treated in the hospital overnight - and was still there Sunday\n",
      "afternoon. He does not yet have an attorney. Tense: Pickering was said\n",
      "to be distraught over the condition of his son - a critical care\n",
      "patient .<EOS><pad>GeorgePickering, 57, allegedly made threat from\n",
      "hospital room . Police said he aimed 9mm pistol at nurse inside\n",
      "Tomball Regional Hospital . Gun was allegedly wrested away from\n",
      "Pickering - who said he had another . After three-hour stand-off with\n",
      "police, he was found to be unarmed . Pickering has been charged with\n",
      "aggravated assault with a deadly weapon .<EOS>\n"
     ]
    }
   ],
   "source": [
    "# prints: [Example][<EOS>][<pad>][Example Summary][<EOS>]\n",
    "print(f'Single example:\\n\\n {detokenize(train_input)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4sDS1WIVaYG"
   },
   "source": [
    "<a name='1.3'></a>\n",
    "\n",
    "## 1.3 Batching with bucketing\n",
    "\n",
    "As in the previous week, we use bucketing to create batches of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oqj1NsbERWQX"
   },
   "outputs": [],
   "source": [
    "# Bucketing to create batched generators.\n",
    "\n",
    "# Buckets are defined in terms of boundaries and batch sizes.\n",
    "# Batch_sizes[i] determines the batch size for items with length < boundaries[i]\n",
    "# So below, we'll take a batch of 16 sentences of length < 128 , 8 of length < 256,\n",
    "# 4 of length < 512. And so on. \n",
    "boundaries =  [128, 256,  512, 1024]\n",
    "batch_sizes = [16,    8,    4,    2, 1]\n",
    "\n",
    "# Create the streams.\n",
    "train_batch_stream = trax.data.BucketByLength(\n",
    "    boundaries, batch_sizes)(train_stream)\n",
    "\n",
    "eval_batch_stream = trax.data.BucketByLength(\n",
    "    boundaries, batch_sizes)(eval_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6M5OA8QRWQb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every execution will result in generation of a different article\n",
    "# Try running this cell multiple times to see how the length of the examples affects the batch size\n",
    "input_batch, _, mask_batch = next(train_batch_stream)\n",
    "\n",
    "# Shape of the input_batch\n",
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "SjNOlljxTGuQ",
    "outputId": "9227c68c-6369-4ce8-8137-506c594f6ad2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  207   476  5029  1968  1202     7    26  4303  3060    35   398    87\n",
      " 22813  3921 11945  1487   285  7919  1202     7    26  1500   320  1764\n",
      "     3    27   104  1008  9355  1833  5602 26158     4  4617 27439  9275\n",
      "  1628  2232   320  4323  2416    87  7935  5478    71 22302   285    31\n",
      "  1001  1353  3210  1248   549   807   145   213   568  2387  2678    70\n",
      "    86  1019   161  1303   320  1151   133    61    10   244   225   711\n",
      "    78     2   213  1309   947    23    46   809   103   457 27439  9275\n",
      "  1628   872 25656  1323  3138    70  1248   213  3179   144   527  2071\n",
      " 10085  1409   824    55   239 25951   412   117 24502 10085  1099  4480\n",
      "  2690   295  9175  6051     4   246   320   172 11945  1487 12451    17\n",
      "   132  2071 10085  2387  1892  5548  6929   379 11945  1487    25  4323\n",
      "  2158    71 22302   285   807   230    78  2071 10085  1409    25  2387\n",
      "  6083   379 18728  5602 26158     4 25951   213   846   117 24502 10085\n",
      "    80   132  2547   320   213 16580     6  7605  7135  3179   379  8229\n",
      "    47   320  4391    31 12084  4382   113  5720  1019   213  1001   536\n",
      "     2  1487  1534   320    18   553   117 14094    80  1279   152  7182\n",
      "  1283     8  6323     4  6323     4  7182  1283    48 11399  1342 13209\n",
      "  1342     8  1263    42     6  1470    42    12   186  6037   558 11884\n",
      "  1033     8  3649 16200 10514    28  2520  1248    38   150   831  3857\n",
      " 15249   320 12547  8006  4402  7227     7     5  6408     3  7182  1283\n",
      "     2    28  1574   179   181    28   346 18691    58  1838   213  7941\n",
      "    59     2   229   897   691    36  3331   412   213   117    82   240\n",
      "  8609  3898   192   297   465    22    39  1151    28   227  7847    78\n",
      "   213 11616     5     3 11884  1033   229  1636   320   385   132   213\n",
      "   671 25137    21   527    15  1922   117  1620    80 15224    70   213\n",
      " 15422 19428   186  7043   566 20064     3  7545    15   705     6   104\n",
      "     6   292   117 18437    16    80   536     2 11884  1033     7     5\n",
      "   548   117 12033    80  1435    15   985   320   385   412    28  1892\n",
      "   157     3     9  2471  1659  2342   132  1195    62  1151    28  3857\n",
      "   659   931   320   213  7935 11447   186   229   553   412   163  4460\n",
      "  6310  1019  1001  7269 13548  2116 13617 10770    28  1782  6037   558\n",
      " 11884  1033    80  1353   553   691  1487   412   163  4460  6310  1019\n",
      "  1001  7269 13548  2116 13617 10770    28 11969     7 11399  1342 13209\n",
      "  1342    80   107  1279   152  7182  1283   229   297   506 13813  1779\n",
      "    49   385   148   412    28  1574   179   181   412    28   346 18691\n",
      "    58   379 13209  1342     2   107  7182  1283     2    23   213  2564\n",
      " 20532 11296   320   385   132   213  1348   527  6374   186   181    78\n",
      "   213   346 11616     4    70    28 26564   285 11945  5478  1692  1006\n",
      "    62  1151    28 14496 16971     3     9   928  1337     7     5   775\n",
      "  4787   229    36  5532  3094   691   213   978   401 11447     2   849\n",
      "    36  3331  5435    22   848   297   357   171    22    49   191    28\n",
      "   608   910   809   213  1001     3   853   213  1017   229    19  1248\n",
      "    38 11945  5478     2    72    25 20684    78   320   213  5548  6929\n",
      "     3  6681  3729   527  7182  1283    28  1718 13099   205   285    41\n",
      "    18   117   369  1613   527   134  3898   171  9775  1049   285   213\n",
      "  7941    59 13813   117  3949   107   579    64   527  2071 10085  2002\n",
      "     9 13099     7     5 20374  5346   565  1435  3088   637  3729 13209\n",
      "  1342     7     5   287    35  4524     5   122    86    31  2907  5478\n",
      "    25   412 13182    21    61     3     9  5548  6929   790     7    26\n",
      " 12451     4    97    72 11945  1487     8  1574   186   231    12   536\n",
      "  1779    25  4651   320   213   133     6    61  1303   379 13361  6876\n",
      "  1019   105   536    77     7     5    92 19277   213 24487     4   213\n",
      "  2524    95  8006  4402  7227     7     5   384   809   432   103  1063\n",
      "     2   412   213  7935   952   320  1621    78    38   290  6942     5\n",
      "  1019  6850  6198  6278   824   357     3  1895     7     5    42     6\n",
      "   121   802   809   278   320 10665   980   213  7935  1013    72   694\n",
      "   869   527   878 14252  3389   324   809   213   448   527   213  6268\n",
      "   951     3 11945  1536   320 18538   382    78  1895  2801   996  1019\n",
      "    31  6695   802   132   546  1930   584     3  7890     8  1574    12\n",
      "  2696 11945     7     5 25677     4   412    41  2530 10665    42     6\n",
      "   121   132   213  6268   951    78  1895  2104     1     0  6323     4\n",
      "  6323     4  7182  1283     2  3649 16200 10514    28   186  1263    42\n",
      "     6  1470    42  1435    38  2071 10085  1409 16346 27439  6774  1628\n",
      "  3496    79    25   316  1279   152  7182  1283     2  6037   558 11884\n",
      "  1033   186 11399  1342 13209  1342   132  9355  1833  5602 26158     4\n",
      "  5548  6929 16346 27439  6774  1628 11945  2530 10665    42     6   121\n",
      "   809   278   132   213  6268   951    78  1895 16346 27439  6774  1628\n",
      "  7935  1536   320 18538   324   132    31   382  1930 16188     4    78\n",
      "   568   441  2104     1     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "# print corresponding integer values\n",
    "print(input_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GD-72TENV2Jk"
   },
   "source": [
    "Things to notice:\n",
    " - First we see the corresponding values of the words.\n",
    " - The first 1, which represents the `<EOS>` tag of the article.\n",
    " - Followed by a 0, which represents a `<pad>` tag.\n",
    " - After the first 0 (`<pad>` tag) the corresponding values are of the words that are used for the summary of the article.\n",
    " - The second 1 represents the `<EOS>` tag for the summary.\n",
    " - All the trailing 0s represent `<pad>` tags which are appended to maintain consistent length (If you don't see them then it would mean it is already of max length)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Bu05ZwbWTE6P",
    "outputId": "3d455bd7-e343-4c25-a467-572d2abd837f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article:\n",
      "\n",
      " They say lightning doesn't strike twice but among some gullible\n",
      "Chelsea fans that phrase doesn't appear to apply. A year ago\n",
      "talkSPORT, managed to dupe some Blues supporters into believing that\n",
      "their club was linked with various players during the January transfer\n",
      "window - only for those names to be made up.And 12 months on, the\n",
      "radio station has been at it again outside Stamford Bridge - with the\n",
      "theme being of Star Wars characters this time around dubbed as\n",
      "'Transfer Wars'. VIDEO Scroll down to see Chelsea fans fooled in Star\n",
      "Wars transfer target prank . Chelsea fans were duped into believing\n",
      "that players based on Star Wars characters were transfer targets .\n",
      "TalkSPORT dubbed the video 'Transfer Wars' in relation to the sci-fi\n",
      "franchise theme . Keen to prove their unrelenting passion for the club\n",
      "though, fans claim to have seen 'trio' JJ Binks (Jar Jar Binks), Artur\n",
      "Detur (R2-D2) and Stew Bacca (Chewbacca) - with all three reported\n",
      "welcome additions to Jose Mourinho's squad. Binks, a centre back or a\n",
      "left winger from the MLS, is described by one fan as the 'new John\n",
      "Terry,' while another says he will be a good signing on the flanks.\n",
      "Bacca is mentioned to play in the similar mould of his older 'brother'\n",
      "Carlos - the Sevilla and Colombia international striker. Unlike his\n",
      "28-year-old 'sibling' though, Bacca's main 'attributes' are his\n",
      "ability to play as a target man. The 6ft 5in forward would be a\n",
      "welcome addition according to the Blues faithful and is seen as an\n",
      "ideal replacement for club legend Didier Drogba. 'Stew Bacca' was seen\n",
      "by fans as an ideal replacement for club legend Didier Drogba . 'Artur\n",
      "Detur' like JJ Binks is another young prospect who can play both as a\n",
      "centre back or as a left winger . Detur, like Binks, has the rare\n",
      "tactical flexibility to play in the heart of defence and or on the\n",
      "left flank - a trait that Chelsea supporters clearly feel would be a\n",
      "bonus commodity. The France star's potential arrival is one relished\n",
      "by the west London faithful, although one fan believes he needs\n",
      "another season before he can make a real impact at the club. Although\n",
      "the force is not with all Chelsea supporters, two were switched on to\n",
      "the prank. Upon hearing of Binks a male duo state that they have\n",
      "'never heard of him,' before querying that the MLS prospect 'sounds\n",
      "like something out of Star Wars.' The duo's suspicions are confirmed\n",
      "upon hearing Detur's name but alas if only their fellow supporters\n",
      "were as clued up. The prank didn't fool these two Chelsea fans (centre\n",
      "and right) though who were wise to the made-up names . Luckily for\n",
      "them though there's no pulling the wool the eyes over Mourinho's side\n",
      "at present it seems, as the Blues continue to fight on all four fronts\n",
      "for silverware this season. Saturday's 2-0 win at home to Newcastle\n",
      "saw the Blues move two points clear of title rivals Manchester City at\n",
      "the top of the Premier League. Chelsea travel to Swansea next on\n",
      "Saturday evening looking for their 16th win in 22 league games. Oscar\n",
      "(centre) scored Chelsea's opener as they beat Newcastle 2-0 in the\n",
      "Premier League on Saturday .<EOS><pad>JarJar Binks, Chewbacca and\n",
      "R2-D2 are all Star Wars characters . Trio were called JJ Binks, Stew\n",
      "Bacca and Artur Detur in talkSPORT prank . Chelsea beat Newcastle 2-0\n",
      "at home in the Premier League on Saturday . Blues travel to Swansea\n",
      "City in their next league fixture on January 17 .<EOS><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><\n",
      "pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "# print the article and its summary\n",
    "print('Article:\\n\\n', detokenize(input_batch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aNFVhgHoncGm"
   },
   "source": [
    "You can see that the data has the following structure:\n",
    "- <span style='color:blue'> [Article] </span> -> `<EOS>` -> `<pad>` -> <span style='color:blue'> [Article Summary] </span> -> `<EOS>` -> (possibly) multiple `<pad>`\n",
    "\n",
    "The loss is taken only on the summary using cross_entropy as loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Un8NHIRoj-1W"
   },
   "source": [
    "<a name='2'></a>\n",
    "# Part 2: Summarization with transformer\n",
    "\n",
    "Now that we have given you the data generator and have handled the preprocessing for you, it is time for you to build your own model. We saved you some time because we know you have already preprocessed data before in this specialization, so we would rather you spend your time doing the next steps. \n",
    "\n",
    "You will be implementing the attention from scratch and then using it in your transformer model. Concretely, you will understand how attention works, how you use it to connect the encoder and the decoder.\n",
    "\n",
    "<img src=\"transformer_decoder_zoomin.png\">\n",
    "\n",
    "<a name='2.1'></a>\n",
    "## 2.1 Dot product attention \n",
    "\n",
    "Now you will implement dot product attention which takes in a query, key, value, and a mask. It returns the output. \n",
    "\n",
    "<img src =\"dotproduct.png\">\n",
    "\n",
    "\n",
    "Here are some helper functions that will help you create tensors and display useful information:\n",
    "   - `create_tensor`  creates a `jax numpy array` from a list of lists.\n",
    "   - `display_tensor` prints out the shape and the actual tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor(t):\n",
    "    \"\"\"Create tensor from list of lists\"\"\"\n",
    "    return jnp.array(t)\n",
    "\n",
    "\n",
    "def display_tensor(t, name):\n",
    "    \"\"\"Display shape and tensor\"\"\"\n",
    "    print(f'{name} shape: {t.shape}\\n')\n",
    "    print(f'{t}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing it yourself, you can play around with a toy example of `dot product attention` without the softmax  operation. Technically it would not be `dot product attention` without the softmax but this is done to avoid giving away too much of the answer and the idea is to display these tensors to give you a sense of how they look like.\n",
    "\n",
    "The formula for attention is this one:\n",
    "\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
    "$$\n",
    "\n",
    "$d_{k}$ stands for the dimension of queries and keys.\n",
    "\n",
    "The `query`, `key`, `value` and `mask` vectors are provided for this example.\n",
    "\n",
    "Notice that the masking is done using very negative values that will yield a similar effect to using $-\\infty $. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "_0x0HJXwRWQk",
    "outputId": "d6d78a8e-e3cc-47af-9584-2bdcdfcca0cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shape: (2, 3)\n",
      "\n",
      "[[1 0 0]\n",
      " [0 1 0]]\n",
      "\n",
      "key shape: (2, 3)\n",
      "\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "value shape: (2, 3)\n",
      "\n",
      "[[0 1 0]\n",
      " [1 0 1]]\n",
      "\n",
      "mask shape: (2, 2)\n",
      "\n",
      "[[ 0.e+00  0.e+00]\n",
      " [-1.e+09  0.e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = create_tensor([[1, 0, 0], [0, 1, 0]])\n",
    "display_tensor(q, 'query')\n",
    "k = create_tensor([[1, 2, 3], [4, 5, 6]])\n",
    "display_tensor(k, 'key')\n",
    "v = create_tensor([[0, 1, 0], [1, 0, 1]])\n",
    "display_tensor(v, 'value')\n",
    "m = create_tensor([[0, 0], [-1e9, 0]])\n",
    "display_tensor(m, 'mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "query shape: (2, 3)\n",
    "\n",
    "[[1 0 0]\n",
    " [0 1 0]]\n",
    "\n",
    "key shape: (2, 3)\n",
    "\n",
    "[[1 2 3]\n",
    " [4 5 6]]\n",
    "\n",
    "value shape: (2, 3)\n",
    "\n",
    "[[0 1 0]\n",
    " [1 0 1]]\n",
    "\n",
    "mask shape: (2, 2)\n",
    "\n",
    "[[ 0.e+00  0.e+00]\n",
    " [-1.e+09  0.e+00]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kVR9u4faRWQo",
    "outputId": "f01ea4ca-4152-4b54-b76a-e4b5917ae2b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query dot key shape: (2, 2)\n",
      "\n",
      "[[0.57735026 2.309401  ]\n",
      " [1.1547005  2.8867514 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_dot_k = q @ k.T / jnp.sqrt(3)\n",
    "display_tensor(q_dot_k, 'query dot key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "query dot key shape: (2, 2)\n",
    "\n",
    "[[0.57735026 2.309401  ]\n",
    " [1.1547005  2.8867514 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked query dot key shape: (2, 2)\n",
      "\n",
      "[[ 5.7735026e-01  2.3094010e+00]\n",
      " [-1.0000000e+09  2.8867514e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "masked = q_dot_k + m\n",
    "display_tensor(masked, 'masked query dot key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "masked query dot key shape: (2, 2)\n",
    "\n",
    "[[ 5.7735026e-01  2.3094010e+00]\n",
    " [-1.0000000e+09  2.8867514e+00]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked query dot key dot value shape: (2, 3)\n",
      "\n",
      "[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n",
      " [ 2.8867514e+00 -1.0000000e+09  2.8867514e+00]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tensor(masked @ v, 'masked query dot key dot value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "masked query dot key dot value shape: (2, 3)\n",
    "\n",
    "[[ 2.3094010e+00  5.7735026e-01  2.3094010e+00]\n",
    " [ 2.8867514e+00 -1.0000000e+09  2.8867514e+00]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the previous dummy tensors to test some of the graded functions, a batch dimension should be added to them so they mimic the shape of real-life examples. The mask is also replaced by a version of it that resembles the one that is used by trax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]]\n",
      "\n",
      "key with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[1 2 3]\n",
      "  [4 5 6]]]\n",
      "\n",
      "value with batch dim shape: (1, 2, 3)\n",
      "\n",
      "[[[0 1 0]\n",
      "  [1 0 1]]]\n",
      "\n",
      "boolean mask shape: (2, 2)\n",
      "\n",
      "[[ True  True]\n",
      " [False  True]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_with_batch = q[None,:]\n",
    "display_tensor(q_with_batch, 'query with batch dim')\n",
    "k_with_batch = k[None,:]\n",
    "display_tensor(k_with_batch, 'key with batch dim')\n",
    "v_with_batch = v[None,:]\n",
    "display_tensor(v_with_batch, 'value with batch dim')\n",
    "m_bool = create_tensor([[True, True], [False, True]])\n",
    "display_tensor(m_bool, 'boolean mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "query with batch dim shape: (1, 2, 3)\n",
    "\n",
    "[[[1 0 0]\n",
    "  [0 1 0]]]\n",
    "\n",
    "key with batch dim shape: (1, 2, 3)\n",
    "\n",
    "[[[1 2 3]\n",
    "  [4 5 6]]]\n",
    "\n",
    "value with batch dim shape: (1, 2, 3)\n",
    "\n",
    "[[[0 1 0]\n",
    "  [1 0 1]]]\n",
    "\n",
    "boolean mask shape: (2, 2)\n",
    "\n",
    "[[ True  True]\n",
    " [False  True]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex01'></a>\n",
    "### Exercise 01\n",
    "\n",
    "**Instructions:** Implement the dot product attention. Concretely, implement the following equation\n",
    "\n",
    "\n",
    "$$\n",
    "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}+{M}\\right) V\\tag{1}\\\n",
    "$$\n",
    "\n",
    "$Q$ - query, \n",
    "$K$ - key, \n",
    "$V$ - values, \n",
    "$M$ - mask, \n",
    "${d_k}$ - depth/dimension of the queries and keys (used for scaling down)\n",
    "\n",
    "You can implement this formula either by `trax` numpy (trax.math.numpy) or regular `numpy` but it is recommended to use `jnp`.\n",
    "\n",
    "Something to take into consideration is that within trax, the masks are tensors of `True/False` values not 0's and $-\\infty$ as in the previous example. Within the graded function don't think of applying the mask by summing up matrices, instead use `jnp.where()` and treat the **mask as a tensor of boolean values with `False` for values that need to be masked and True for the ones that don't.**\n",
    "\n",
    "Also take into account that the real tensors are far more complex than the toy ones you just played with. Because of this avoid using shortened operations such as `@` for dot product or `.T` for transposing. Use `jnp.matmul()` and `jnp.swapaxes()` instead.\n",
    "\n",
    "This is the self-attention block for the transformer decoder. Good luck!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSauPt0NUl_o"
   },
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: DotProductAttention\n",
    "def DotProductAttention(query, key, value, mask):\n",
    "    \"\"\"Dot product self-attention.\n",
    "    Args:\n",
    "        query (jax.interpreters.xla.DeviceArray): array of query representations with shape (L_q by d)\n",
    "        key (jax.interpreters.xla.DeviceArray): array of key representations with shape (L_k by d)\n",
    "        value (jax.interpreters.xla.DeviceArray): array of value representations with shape (L_k by d) where L_v = L_k\n",
    "        mask (jax.interpreters.xla.DeviceArray): attention-mask, gates attention with shape (L_q by L_k)\n",
    "\n",
    "    Returns:\n",
    "        jax.interpreters.xla.DeviceArray: Self-attention array for q, k, v arrays. (L_q by L_k)\n",
    "    \"\"\"\n",
    "\n",
    "    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"Embedding dimensions of q, k, v aren't all the same\"\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # Save depth/dimension of the query embedding for scaling down the dot product\n",
    "    depth = query.shape[-1]\n",
    "\n",
    "    # Calculate scaled query key dot product according to formula above\n",
    "    dots = jnp.matmul(query, jnp.swapaxes(key, -1, -2)) / jnp.sqrt(depth)\n",
    "    \n",
    "    # Apply the mask\n",
    "    if mask is not None: # The 'None' in this line does not need to be replaced\n",
    "        dots = jnp.where(mask, dots, jnp.full_like(dots, -1e9))\n",
    "    \n",
    "    # Softmax formula implementation\n",
    "    # Use trax.fastmath.logsumexp of dots to avoid underflow by division by large numbers\n",
    "    # Hint: Last axis should be used and keepdims should be True\n",
    "    # Note: softmax = e^(dots - logsumexp(dots)) = E^dots / sumexp(dots)\n",
    "    logsumexp = trax.fastmath.logsumexp(dots, axis=-1, keepdims=True)\n",
    "\n",
    "    # Take exponential of dots minus logsumexp to get softmax\n",
    "    # Use jnp.exp()\n",
    "    dots = jnp.exp(dots - logsumexp)\n",
    "\n",
    "\n",
    "    # Multiply dots by value to get self-attention\n",
    "    # Use jnp.matmul()\n",
    "    attention = jnp.matmul(dots, value)\n",
    "\n",
    "    ## END CODE HERE ###\n",
    "    \n",
    "    return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8o0K7VWKRWQw",
    "outputId": "1c51af3a-5f11-480f-b33b-419072d8298c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[0.8496746 , 0.15032545, 0.8496746 ],\n",
       "              [1.        , 0.        , 1.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DotProductAttention(q_with_batch, k_with_batch, v_with_batch, m_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "DeviceArray([[[0.8496746 , 0.15032545, 0.8496746 ],\n",
    "              [1.        , 0.        , 1.        ]]], dtype=float32)\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2y2PSiLVRWQ2"
   },
   "source": [
    "<a name='2.2'></a>\n",
    "\n",
    "## 2.2 Causal Attention\n",
    "\n",
    "Now you are going to implement causal attention: multi-headed attention with a mask to attend only to words that occurred before. \n",
    "\n",
    "<img src = \"causal.png\">\n",
    "\n",
    "In the image above, a word can see everything that is before it, but not what is after it. To implement causal attention, you will have to transform vectors and do many reshapes. You will need to implement the functions below.\n",
    "\n",
    "\n",
    "<a name='ex02'></a>\n",
    "### Exercise 02\n",
    "\n",
    "Implement the following functions that will be needed for Causal Attention:\n",
    "\n",
    "- <span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (batch_size, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size $\\times$ n_heads, seqlen, d_head).\n",
    "- <span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention.\n",
    "- <span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (batch_size, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. \n",
    "\n",
    "Next there are some toy tensors which may serve to give you an idea of the data shapes and opperations involved in Causal Attention. They are also useful to test out your functions! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "VRH67YcrRWQ3",
    "outputId": "847a9416-877a-4246-c738-0eacdf46de59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query matrix (2D tensor) shape: (2, 3)\n",
      "\n",
      "[[1 0 0]\n",
      " [0 1 0]]\n",
      "\n",
      "batch of two (multi-head) collections of query matrices (4D tensor) shape: (2, 2, 2, 3)\n",
      "\n",
      "[[[[1 0 0]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]]]\n",
      "\n",
      "\n",
      " [[[1 0 0]\n",
      "   [0 1 0]]\n",
      "\n",
      "  [[1 0 0]\n",
      "   [0 1 0]]]]\n",
      "\n",
      "one batch of concatenated heads of query matrices (3d tensor) shape: (1, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n",
      "three batches of concatenated heads of query matrices (3d tensor) shape: (3, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tensor2d = create_tensor(q)\n",
    "display_tensor(tensor2d, 'query matrix (2D tensor)')\n",
    "\n",
    "tensor4d2b = create_tensor([[q, q], [q, q]])\n",
    "display_tensor(tensor4d2b, 'batch of two (multi-head) collections of query matrices (4D tensor)')\n",
    "\n",
    "tensor3dc = create_tensor([jnp.concatenate([q, q], axis = -1)])\n",
    "display_tensor(tensor3dc, 'one batch of concatenated heads of query matrices (3d tensor)')\n",
    "\n",
    "tensor3dc3b = create_tensor([jnp.concatenate([q, q], axis = -1), jnp.concatenate([q, q], axis = -1), jnp.concatenate([q, q], axis = -1)])\n",
    "display_tensor(tensor3dc3b, 'three batches of concatenated heads of query matrices (3d tensor)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know that the following 3 functions would normally be defined within the `CausalAttention` function further below. \n",
    "\n",
    "However this makes these functions harder to test. Because of this, these functions are shown individually using a `closure` (when necessary) that simulates them being inside of the `CausalAttention` function. This is done because they rely on some variables that can be accessed from within `CausalAttention`.\n",
    "\n",
    "### Support Functions\n",
    "\n",
    "<span style='color:blue'> compute_attention_heads </span>: Gets an input $x$ of dimension (batch_size, seqlen, n_heads $\\times$ d_head) and splits the last (depth) dimension and stacks it to the zeroth dimension to allow matrix multiplication (batch_size $\\times$ n_heads, seqlen, d_head).\n",
    "\n",
    "**For the closures you only have to fill the inner function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: compute_attention_heads_closure\n",
    "def compute_attention_heads_closure(n_heads, d_head):\n",
    "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
    "    Args:\n",
    "        d_head (int):  dimensionality of heads.\n",
    "        n_heads (int): number of attention heads.\n",
    "    Returns:\n",
    "        function: compute_attention_heads function\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_attention_heads(x):\n",
    "        \"\"\" Compute the attention heads.\n",
    "        Args:\n",
    "            x (jax.interpreters.xla.DeviceArray): tensor with shape (batch_size, seqlen, n_heads X d_head).\n",
    "        Returns:\n",
    "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size X n_heads, seqlen, d_head).\n",
    "        \"\"\"\n",
    "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "        \n",
    "        # Size of the x's batch dimension\n",
    "        batch_size = x.shape[0]\n",
    "        # Length of the sequence\n",
    "        # Should be size of x's first dimension without counting the batch dim\n",
    "        seqlen = x.shape[1]\n",
    "        # Reshape x using jnp.reshape()\n",
    "        # batch_size, seqlen, n_heads*d_head -> batch_size, seqlen, n_heads, d_head\n",
    "        x  = jnp.reshape(x, (batch_size, seqlen, n_heads, d_head))\n",
    "        # Transpose x using jnp.transpose()\n",
    "        # batch_size, seqlen, n_heads, d_head -> batch_size, n_heads, seqlen, d_head\n",
    "        # Note that the values within the tuple are the indexes of the dimensions of x and you must rearrange them\n",
    "        x = jnp.transpose(x, (0, 2, 1, 3))\n",
    "        # Reshape x using jnp.reshape()\n",
    "        # batch_size, n_heads, seqlen, d_head -> batch_size*n_heads, seqlen, d_head\n",
    "        x = jnp.reshape(x, (-1, seqlen, d_head))\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    return compute_attention_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape: (3, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n",
      "output tensor shape: (6, 2, 3)\n",
      "\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tensor(tensor3dc3b, \"input tensor\")\n",
    "result_cah = compute_attention_heads_closure(2,3)(tensor3dc3b)\n",
    "display_tensor(result_cah, \"output tensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "input tensor shape: (3, 2, 6)\n",
    "\n",
    "[[[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]]\n",
    "\n",
    "output tensor shape: (6, 2, 3)\n",
    "\n",
    "[[[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'> dot_product_self_attention </span>: Creates a mask matrix with `False` values above the diagonal and `True` values below and calls DotProductAttention which implements dot product self attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots=jnp.ones((5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[ 1.e+00, -1.e+09, -1.e+09, -1.e+09, -1.e+09],\n",
       "              [ 1.e+00,  1.e+00, -1.e+09, -1.e+09, -1.e+09],\n",
       "              [ 1.e+00,  1.e+00,  1.e+00, -1.e+09, -1.e+09],\n",
       "              [ 1.e+00,  1.e+00,  1.e+00,  1.e+00, -1.e+09],\n",
       "              [ 1.e+00,  1.e+00,  1.e+00,  1.e+00,  1.e+00]]],            dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = jnp.tril(jnp.ones((1, 5, 5), dtype=jnp.bool_), k=0)\n",
    "mask\n",
    "dots = jnp.where(mask, dots, jnp.full_like(dots, -1e9))\n",
    "dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: dot_product_self_attention\n",
    "def dot_product_self_attention(q, k, v):\n",
    "    \"\"\" Masked dot product self attention.\n",
    "    Args:\n",
    "        q (jax.interpreters.xla.DeviceArray): queries.\n",
    "        k (jax.interpreters.xla.DeviceArray): keys.\n",
    "        v (jax.interpreters.xla.DeviceArray): values.\n",
    "    Returns:\n",
    "        jax.interpreters.xla.DeviceArray: masked dot product self attention tensor.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # Hint: mask size should be equal to L_q. Remember that q has shape (batch_size, L_q, d)\n",
    "    mask_size = q.shape[-2]\n",
    "\n",
    "    # Creates a matrix with ones below the diagonal and 0s above. It should have shape (1, mask_size, mask_size)\n",
    "    # Notice that 1's and 0's get casted to True/False by setting dtype to jnp.bool_\n",
    "    # Use jnp.tril() - Lower triangle of an array and jnp.ones()\n",
    "    mask = jnp.tril(jnp.ones((1, mask_size, mask_size), dtype=jnp.bool_), k=0)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return DotProductAttention(q, k, v, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[0.        , 1.        , 0.        ],\n",
       "              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_self_attention(q_with_batch, k_with_batch, v_with_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "DeviceArray([[[0.        , 1.        , 0.        ],\n",
    "              [0.8496746 , 0.15032543, 0.8496746 ]]], dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:blue'> compute_attention_output </span>: Undoes compute_attention_heads by splitting first (vertical) dimension and stacking in the last (depth) dimension (batch_size, seqlen, n_heads $\\times$ d_head). These operations concatenate (stack/merge) the heads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4\n",
    "# GRADED FUNCTION: compute_attention_output_closure\n",
    "def compute_attention_output_closure(n_heads, d_head):\n",
    "    \"\"\" Function that simulates environment inside CausalAttention function.\n",
    "    Args:\n",
    "        d_head (int):  dimensionality of heads.\n",
    "        n_heads (int): number of attention heads.\n",
    "    Returns:\n",
    "        function: compute_attention_output function\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_attention_output(x):\n",
    "        \"\"\" Compute the attention output.\n",
    "        Args:\n",
    "            x (jax.interpreters.xla.DeviceArray): tensor with shape (batch_size X n_heads, seqlen, d_head).\n",
    "        Returns:\n",
    "            jax.interpreters.xla.DeviceArray: reshaped tensor with shape (batch_size, seqlen, n_heads X d_head).\n",
    "        \"\"\"\n",
    "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "        \n",
    "        # Length of the sequence\n",
    "        # Should be size of x's first dimension without counting the batch dim\n",
    "        seqlen = x.shape[1]\n",
    "        # Reshape x using jnp.reshape() to shape (batch_size, n_heads, seqlen, d_head)\n",
    "        x = jnp.reshape(x, ( -1, n_heads, seqlen, d_head))\n",
    "        # Transpose x using jnp.transpose() to shape (batch_size, seqlen, n_heads, d_head)\n",
    "        x = jnp.transpose(x, ( 0, 2, 1 , 3))\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Reshape to allow to concatenate the heads\n",
    "        return jnp.reshape(x, (-1, seqlen, n_heads * d_head))\n",
    "    \n",
    "    return compute_attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor shape: (6, 2, 3)\n",
      "\n",
      "[[[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 0]\n",
      "  [0 1 0]]]\n",
      "\n",
      "output tensor shape: (3, 2, 6)\n",
      "\n",
      "[[[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]\n",
      "\n",
      " [[1 0 0 1 0 0]\n",
      "  [0 1 0 0 1 0]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_tensor(result_cah, \"input tensor\")\n",
    "result_cao = compute_attention_output_closure(2,3)(result_cah)\n",
    "display_tensor(result_cao, \"output tensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "input tensor shape: (6, 2, 3)\n",
    "\n",
    "[[[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]\n",
    "\n",
    " [[1 0 0]\n",
    "  [0 1 0]]]\n",
    "\n",
    "output tensor shape: (3, 2, 6)\n",
    "\n",
    "[[[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]\n",
    "\n",
    " [[1 0 0 1 0 0]\n",
    "  [0 1 0 0 1 0]]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Attention Function\n",
    "\n",
    "Now it is time for you to put everything together within the `CausalAttention` or Masked multi-head attention function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"masked-attention.png\"> \n",
    "\n",
    "**Instructions:** Implement the causal attention.\n",
    "Your model returns the causal attention through a $tl.Serial$ with the following:\n",
    "\n",
    "- <span style='color:blue'> [tl.Branch](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Branch) </span>: consisting of 3 [tl.Dense(d_feature), ComputeAttentionHeads] to account for the queries, keys, and values.\n",
    "- <span style='color:blue'> [tl.Fn](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn)</span>: Takes in dot_product_self_attention function and uses it to compute the dot product using $Q$, $K$, $V$.\n",
    "- <span style='color:blue'> [tl.Fn](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn)</span>: Takes in compute_attention_output_closure to allow for parallel computing.\n",
    "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense)</span>: Final Dense layer, with dimension `d_feature`.\n",
    "\n",
    "Remember that in order for trax to properly handle the functions you just defined, they need to be added as layers using the [`tl.Fn()`](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.base.Fn) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9Adn6DtRWRG"
   },
   "outputs": [],
   "source": [
    "# UNQ_C5\n",
    "# GRADED FUNCTION: CausalAttention\n",
    "def CausalAttention(d_feature, \n",
    "                    n_heads, \n",
    "                    compute_attention_heads_closure=compute_attention_heads_closure,\n",
    "                    dot_product_self_attention=dot_product_self_attention,\n",
    "                    compute_attention_output_closure=compute_attention_output_closure,\n",
    "                    mode='train'):\n",
    "    \"\"\"Transformer-style multi-headed causal attention.\n",
    "\n",
    "    Args:\n",
    "        d_feature (int):  dimensionality of feature embedding.\n",
    "        n_heads (int): number of attention heads.\n",
    "        compute_attention_heads_closure (function): Closure around compute_attention heads.\n",
    "        dot_product_self_attention (function): dot_product_self_attention function. \n",
    "        compute_attention_output_closure (function): Closure around compute_attention_output. \n",
    "        mode (str): 'train' or 'eval'.\n",
    "\n",
    "    Returns:\n",
    "        trax.layers.combinators.Serial: Multi-headed self-attention model.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert d_feature % n_heads == 0\n",
    "    d_head = d_feature // n_heads\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # HINT: The second argument to tl.Fn() is an uncalled function (without the parentheses)\n",
    "    # Since you are dealing with closures you might need to call the outer \n",
    "    # function with the correct parameters to get the actual uncalled function.\n",
    "    ComputeAttentionHeads = tl.Fn('AttnHeads', compute_attention_heads_closure(n_heads, d_head), n_out=1)\n",
    "        \n",
    "\n",
    "    return tl.Serial(\n",
    "        tl.Branch( # creates three towers for one input, takes activations and creates queries keys and values\n",
    "            [tl.Dense(d_feature), ComputeAttentionHeads], # queries\n",
    "            [tl.Dense(d_feature), ComputeAttentionHeads], # keys\n",
    "            [tl.Dense(d_feature), ComputeAttentionHeads], # values\n",
    "        ),\n",
    "        \n",
    "        tl.Fn('DotProductAttn', dot_product_self_attention, n_out=1), # takes QKV\n",
    "        # HINT: The second argument to tl.Fn() is an uncalled function\n",
    "        # Since you are dealing with closures you might need to call the outer \n",
    "        # function with the correct parameters to get the actual uncalled function.\n",
    "        tl.Fn('AttnOutput', compute_attention_output_closure(n_heads, d_head), n_out=1), # to allow for parallel\n",
    "        tl.Dense(d_feature) # Final dense layer\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  Branch_out3[\n",
      "    [Dense_512, AttnHeads]\n",
      "    [Dense_512, AttnHeads]\n",
      "    [Dense_512, AttnHeads]\n",
      "  ]\n",
      "  DotProductAttn_in3\n",
      "  AttnOutput\n",
      "  Dense_512\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the causal attention model\n",
    "print(CausalAttention(d_feature=512, n_heads=8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "Serial[\n",
    "  Branch_out3[\n",
    "    [Dense_512, AttnHeads]\n",
    "    [Dense_512, AttnHeads]\n",
    "    [Dense_512, AttnHeads]\n",
    "  ]\n",
    "  DotProductAttn_in3\n",
    "  AttnOutput\n",
    "  Dense_512\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6zwtPjqRWRJ"
   },
   "source": [
    "<a name='2.3'></a>\n",
    "\n",
    "## 2.3 Transformer decoder block\n",
    "\n",
    "Now that you have implemented the causal part of the transformer, you will implement the transformer decoder block. Concretely you will be implementing this image now.\n",
    "\n",
    "<img src = \"transformer_decoder_1.png\" style = \"height:300px\"> \n",
    "\n",
    "To implement this function, you will have to call the `CausalAttention` or Masked multi-head attention function you implemented above. You will have to add a feedforward which consists of: \n",
    "\n",
    "- <span style='color:blue'> [tl.LayerNorm](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) </span>: used to layer normalize\n",
    "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: the dense layer\n",
    "- <span style='color:blue'> [ff_activation](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.activation_fns.Relu) </span>: feed forward activation (we use ReLu) here.\n",
    "- <span style='color:blue'> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout) </span>: dropout layer\n",
    "- <span style='color:blue'> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: dense layer\n",
    "- <span style='color:blue'> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout) </span>: dropout layer\n",
    "\n",
    "Finally once you implement the feedforward, you can go ahead and implement the entire block using: \n",
    "\n",
    "- <span style='color:blue'> [tl.Residual](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) </span>: takes in the tl.LayerNorm(), causal attention block, tl.dropout. \n",
    "\n",
    "- <span style='color:blue'> [tl.Residual](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual) </span>: takes in the feedforward block you will implement. \n",
    "\n",
    "<a name='ex03'></a>\n",
    "### Exercise 03\n",
    "**Instructions:** Implement the transformer decoder block. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKOxnRbp1K5U"
   },
   "outputs": [],
   "source": [
    "# UNQ_C6\n",
    "# GRADED FUNCTION: DecoderBlock\n",
    "def DecoderBlock(d_model, d_ff, n_heads,\n",
    "                 dropout, mode, ff_activation):\n",
    "    \"\"\"Returns a list of layers that implements a Transformer decoder block.\n",
    "\n",
    "    The input is an activation tensor.\n",
    "\n",
    "    Args:\n",
    "        d_model (int):  depth of embedding.\n",
    "        d_ff (int): depth of feed-forward layer.\n",
    "        n_heads (int): number of attention heads.\n",
    "        dropout (float): dropout rate (how much to drop out).\n",
    "        mode (str): 'train' or 'eval'.\n",
    "        ff_activation (function): the non-linearity in feed-forward layer.\n",
    "\n",
    "    Returns:\n",
    "        list: list of trax.layers.combinators.Serial that maps an activation tensor to an activation tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # Create masked multi-head attention block using CausalAttention function\n",
    "    causal_attention = CausalAttention( \n",
    "                        d_model,\n",
    "                        n_heads=n_heads,\n",
    "                        mode=mode\n",
    "                        )\n",
    "\n",
    "    # Create feed-forward block (list) with two dense layers with dropout and input normalized\n",
    "    feed_forward = [ \n",
    "        # Normalize layer inputs\n",
    "        tl.LayerNorm(),\n",
    "        # Add first feed forward (dense) layer (don't forget to set the correct value for n_units)\n",
    "        tl.Dense(d_ff),\n",
    "        # Add activation function passed in as a parameter (you need to call it!)\n",
    "        ff_activation(), # Generally ReLU\n",
    "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
    "        tl.Dropout(rate=dropout, mode=mode),\n",
    "        # Add second feed forward layer (don't forget to set the correct value for n_units)\n",
    "        tl.Dense(d_model),\n",
    "        # Add dropout with rate and mode specified (i.e., don't use dropout during evaluation)\n",
    "        tl.Dropout(rate=dropout,mode=mode)\n",
    "    ]\n",
    "\n",
    "    # Add list of two Residual blocks: the attention with normalization and dropout and feed-forward blocks\n",
    "    return [\n",
    "      tl.Residual(\n",
    "          # Normalize layer input\n",
    "          tl.LayerNorm(),\n",
    "          # Add causal attention block previously defined (without parentheses)\n",
    "          causal_attention,\n",
    "          # Add dropout with rate and mode specified\n",
    "          tl.Dropout(rate=dropout, mode=mode)\n",
    "        ),\n",
    "      tl.Residual(\n",
    "          # Add feed forward block (without parentheses)\n",
    "          feed_forward\n",
    "        ),\n",
    "      ]\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Serial[\n",
      "  Branch_out2[\n",
      "    None\n",
      "    Serial[\n",
      "      LayerNorm\n",
      "      Serial[\n",
      "        Branch_out3[\n",
      "          [Dense_512, AttnHeads]\n",
      "          [Dense_512, AttnHeads]\n",
      "          [Dense_512, AttnHeads]\n",
      "        ]\n",
      "        DotProductAttn_in3\n",
      "        AttnOutput\n",
      "        Dense_512\n",
      "      ]\n",
      "      Dropout\n",
      "    ]\n",
      "  ]\n",
      "  Add_in2\n",
      "], Serial[\n",
      "  Branch_out2[\n",
      "    None\n",
      "    Serial[\n",
      "      LayerNorm\n",
      "      Dense_2048\n",
      "      Relu\n",
      "      Dropout\n",
      "      Dense_512\n",
      "      Dropout\n",
      "    ]\n",
      "  ]\n",
      "  Add_in2\n",
      "]]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the decoder block\n",
    "print(DecoderBlock(d_model=512, d_ff=2048, n_heads=8, dropout=0.1, mode='train', ff_activation=tl.Relu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "[Serial[\n",
    "  Branch_out2[\n",
    "    None\n",
    "    Serial[\n",
    "      LayerNorm\n",
    "      Serial[\n",
    "        Branch_out3[\n",
    "          [Dense_512, AttnHeads]\n",
    "          [Dense_512, AttnHeads]\n",
    "          [Dense_512, AttnHeads]\n",
    "        ]\n",
    "        DotProductAttn_in3\n",
    "        AttnOutput\n",
    "        Dense_512\n",
    "      ]\n",
    "      Dropout\n",
    "    ]\n",
    "  ]\n",
    "  Add_in2\n",
    "], Serial[\n",
    "  Branch_out2[\n",
    "    None\n",
    "    Serial[\n",
    "      LayerNorm\n",
    "      Dense_2048\n",
    "      Relu\n",
    "      Dropout\n",
    "      Dense_512\n",
    "      Dropout\n",
    "    ]\n",
    "  ]\n",
    "  Add_in2\n",
    "]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoFv-nfLRWRN",
    "lines_to_next_cell": 0
   },
   "source": [
    "<a name='2.4'></a>\n",
    "## 2.4 Transformer Language Model\n",
    "\n",
    "You will now bring it all together. In this part you will use all the subcomponents you previously built to make the final model. Concretely, here is the image you will be implementing. \n",
    "<img src = \"transformer_decoder.png\" style = \"height:400px\">\n",
    "\n",
    "    \n",
    "<a name='ex04'></a>\n",
    "### Exercise 04\n",
    "**Instructions:** Previously you coded the decoder block. Now you will code the transformer language model. Here is what you will need. \n",
    "\n",
    "- <span style=\"color:blue\"> positional_enconder </span>- a list containing the following layers:\n",
    "    - <span style=\"color:blue\"> [tl.Embedding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Embedding)\n",
    "    - <span style=\"color:blue\"> [tl.Dropout](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dropout)\n",
    "    - <span style=\"color:blue\"> [tl.PositionalEncoding](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.PositionalEncoding)\n",
    "\n",
    "- A list of `n_layers` <span style=\"color:blue\"> decoder blocks</span>.\n",
    "- <span style=\"color:blue\"> [tl.Serial](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Serial): </span> takes in the following layers or lists of layers:\n",
    "    - <span style=\"color:blue\"> [tl.ShiftRight](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.attention.ShiftRight): </span>: shift the tensor to the right by padding on axis 1.\n",
    "    - <span style=\"color:blue\"> positional_encoder </span>: encodes the text positions.\n",
    "    - <span style=\"color:blue\"> decoder_blocks </span>: the ones you created.\n",
    "    - <span style=\"color:blue\"> [tl.LayerNorm](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.normalization.LayerNorm) </span>: a layer norm.\n",
    "    - <span style=\"color:blue\"> [tl.Dense](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.Dense) </span>: takes in the vocab_size.\n",
    "    - <span style=\"color:blue\"> [tl.LogSoftmax](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.core.LogSoftmax) </span>: to predict.\n",
    "    \n",
    "Go go go!! You can do it :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yi4LJO1RWRS"
   },
   "outputs": [],
   "source": [
    "# UNQ_C7\n",
    "# GRADED FUNCTION: TransformerLM\n",
    "def TransformerLM(vocab_size=33300,\n",
    "                  d_model=512,\n",
    "                  d_ff=2048,\n",
    "                  n_layers=6,\n",
    "                  n_heads=8,\n",
    "                  dropout=0.1,\n",
    "                  max_len=4096,\n",
    "                  mode='train',\n",
    "                  ff_activation=tl.Relu):\n",
    "    \"\"\"Returns a Transformer language model.\n",
    "\n",
    "    The input to the model is a tensor of tokens. (This model uses only the\n",
    "    decoder part of the overall Transformer.)\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): vocab size.\n",
    "        d_model (int):  depth of embedding.\n",
    "        d_ff (int): depth of feed-forward layer.\n",
    "        n_layers (int): number of decoder layers.\n",
    "        n_heads (int): number of attention heads.\n",
    "        dropout (float): dropout rate (how much to drop out).\n",
    "        max_len (int): maximum symbol length for positional encoding.\n",
    "        mode (str): 'train', 'eval' or 'predict', predict mode is for fast inference.\n",
    "        ff_activation (function): the non-linearity in feed-forward layer.\n",
    "\n",
    "    Returns:\n",
    "        trax.layers.combinators.Serial: A Transformer language model as a layer that maps from a tensor of tokens\n",
    "        to activations over a vocab set.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # Embedding inputs and positional encoder\n",
    "    positional_encoder = [ \n",
    "        # Add embedding layer of dimension (vocab_size, d_model)\n",
    "        tl.Embedding(vocab_size, d_model),\n",
    "        # Use dropout with rate and mode specified\n",
    "        tl.Dropout(rate=dropout, mode=mode),\n",
    "        # Add positional encoding layer with maximum input length and mode specified\n",
    "        tl.PositionalEncoding(max_len=max_len, mode=mode)]\n",
    "\n",
    "    # Create stack (list) of decoder blocks with n_layers with necessary parameters\n",
    "    decoder_blocks = [ \n",
    "        DecoderBlock(d_model, d_ff, n_heads,\n",
    "                    dropout, mode, ff_activation) for _ in range(n_layers)]\n",
    "\n",
    "    # Create the complete model as written in the figure\n",
    "    return tl.Serial(\n",
    "        # Use teacher forcing (feed output of previous step to current step)\n",
    "        tl.ShiftRight(mode=mode), # Specify the mode!\n",
    "        # Add positional encoder\n",
    "        positional_encoder,\n",
    "        # Add decoder blocks\n",
    "        decoder_blocks,\n",
    "        # Normalize layer\n",
    "        tl.LayerNorm(),\n",
    "\n",
    "        # Add dense layer of vocab_size (since need to select a word to translate to)\n",
    "        # (a.k.a., logits layer. Note: activation already set by ff_activation)\n",
    "        tl.Dense(vocab_size),\n",
    "        # Get probabilities with Logsoftmax\n",
    "        tl.LogSoftmax()\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial[\n",
      "  ShiftRight(1)\n",
      "  Embedding_33300_512\n",
      "  Dropout\n",
      "  PositionalEncoding\n",
      "  Serial[\n",
      "    Branch_out2[\n",
      "      None\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "        Serial[\n",
      "          Branch_out3[\n",
      "            [Dense_512, AttnHeads]\n",
      "            [Dense_512, AttnHeads]\n",
      "            [Dense_512, AttnHeads]\n",
      "          ]\n",
      "          DotProductAttn_in3\n",
      "          AttnOutput\n",
      "          Dense_512\n",
      "        ]\n",
      "        Dropout\n",
      "      ]\n",
      "    ]\n",
      "    Add_in2\n",
      "  ]\n",
      "  Serial[\n",
      "    Branch_out2[\n",
      "      None\n",
      "      Serial[\n",
      "        LayerNorm\n",
      "        Dense_2048\n",
      "        Relu\n",
      "        Dropout\n",
      "        Dense_512\n",
      "        Dropout\n",
      "      ]\n",
      "    ]\n",
      "    Add_in2\n",
      "  ]\n",
      "  LayerNorm\n",
      "  Dense_33300\n",
      "  LogSoftmax\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the Transformer\n",
    "print(TransformerLM(n_layers=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "Serial[\n",
    "  ShiftRight(1)\n",
    "  Embedding_33300_512\n",
    "  Dropout\n",
    "  PositionalEncoding\n",
    "  Serial[\n",
    "    Branch_out2[\n",
    "      None\n",
    "      Serial[\n",
    "        LayerNorm\n",
    "        Serial[\n",
    "          Branch_out3[\n",
    "            [Dense_512, AttnHeads]\n",
    "            [Dense_512, AttnHeads]\n",
    "            [Dense_512, AttnHeads]\n",
    "          ]\n",
    "          DotProductAttn_in3\n",
    "          AttnOutput\n",
    "          Dense_512\n",
    "        ]\n",
    "        Dropout\n",
    "      ]\n",
    "    ]\n",
    "    Add_in2\n",
    "  ]\n",
    "  Serial[\n",
    "    Branch_out2[\n",
    "      None\n",
    "      Serial[\n",
    "        LayerNorm\n",
    "        Dense_2048\n",
    "        Relu\n",
    "        Dropout\n",
    "        Dense_512\n",
    "        Dropout\n",
    "      ]\n",
    "    ]\n",
    "    Add_in2\n",
    "  ]\n",
    "  LayerNorm\n",
    "  Dense_33300\n",
    "  LogSoftmax\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRRKnoAdvmJ7"
   },
   "source": [
    "<a name='3'></a>\n",
    "# Part 3: Training\n",
    "\n",
    "Now you are going to train your model. As usual, you have to define the cost function, the optimizer, and decide whether you will be training it on a `gpu` or `cpu`. In this case, you will train your model on a cpu for a few steps and we will load in a pre-trained model that you can use to predict with your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1lkVebQRWRV"
   },
   "source": [
    "<a name='3.1'></a>\n",
    "### 3.1 Training the model\n",
    "\n",
    "You will now write a function that takes in your model and trains it. To train your model you have to decide how many times you want to iterate over the entire data set. Each iteration is defined as an `epoch`. For each epoch, you have to go over all the data, using your training iterator.\n",
    "\n",
    "<a name='ex05'></a>\n",
    "### Exercise 05\n",
    "**Instructions:** Implement the `train_model` program below to train the neural network above. Here is a list of things you should do:\n",
    "\n",
    "- Create the train task by calling [`trax.supervised.training.TrainTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.TrainTask) and pass in the following: \n",
    "    - <span style='color:blue'> labeled_data </span> = train_gen\n",
    "    - <span style='color:blue'> loss_fn </span> = [tl.CrossEntropyLoss()](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.CrossEntropyLoss)\n",
    "    - <span style='color:blue'> optimizer </span> = [trax.optimizers.Adam(0.01)](https://trax-ml.readthedocs.io/en/latest/trax.optimizers.html#trax.optimizers.adam.Adam)\n",
    "    - <span style='color:blue'> lr_schedule </span> = [lr_schedule](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.lr_schedules.warmup_and_rsqrt_decay)\n",
    "\n",
    "\n",
    "- Create the eval task by calling [`trax.supervised.training.EvalTask`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.EvalTask) and pass in the following: \n",
    "    - <span style='color:blue'> labeled_data </span> = eval_gen\n",
    "    - <span style='color:blue'> metrics </span> = tl.CrossEntropyLoss() and [tl.Accuracy()](https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.metrics.Accuracy)\n",
    "    \n",
    "    \n",
    "- Create the training loop by calling [`trax.supervised.Training.Loop`](https://trax-ml.readthedocs.io/en/latest/trax.supervised.html#trax.supervised.training.Loop) and pass in the following: \n",
    "    - <span style='color:blue'> TransformerLM </span> \n",
    "    - <span style='color:blue'> train_task </span> \n",
    "    - <span style='color:blue'> eval_task </span> = [eval_task]\n",
    "    - <span style='color:blue'> output_dir</span> = output_dir\n",
    "    \n",
    "You will be using a cross entropy loss, with Adam optimizer. Please read the [Trax](https://trax-ml.readthedocs.io/en/latest/index.html) documentation to get a full understanding. \n",
    "\n",
    "The training loop that this function returns can be runned using the `run()` method by passing in the desired number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gM2gpu4xvjtX"
   },
   "outputs": [],
   "source": [
    "from trax.supervised import training\n",
    "\n",
    "# UNQ_C8\n",
    "# GRADED FUNCTION: train_model\n",
    "def training_loop(TransformerLM, train_gen, eval_gen, output_dir = \"~/model\"):\n",
    "    '''\n",
    "    Input:\n",
    "        TransformerLM (trax.layers.combinators.Serial): The model you are building.\n",
    "        train_gen (generator): Training stream of data.\n",
    "        eval_gen (generator): Evaluation stream of data.\n",
    "        output_dir (str): folder to save your file.\n",
    "        \n",
    "    Returns:\n",
    "        trax.supervised.training.Loop: Training loop.\n",
    "    '''\n",
    "    output_dir = os.path.expanduser(output_dir)  # trainer is an object\n",
    "    lr_schedule = trax.lr.warmup_and_rsqrt_decay(n_warmup_steps=1000, max_value=0.01)\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    train_task = training.TrainTask( \n",
    "      labeled_data=train_gen, # The training generator\n",
    "      loss_layer=tl.CrossEntropyLoss(), # Loss function \n",
    "      optimizer=trax.optimizers.Adam(0.01), # Optimizer (Don't forget to set LR to 0.01)\n",
    "      lr_schedule=lr_schedule,\n",
    "      n_steps_per_checkpoint=10\n",
    "    )\n",
    "\n",
    "    eval_task = training.EvalTask( \n",
    "      labeled_data=eval_gen, # The evaluation generator\n",
    "      metrics=[tl.CrossEntropyLoss(), tl.Accuracy()] # CrossEntropyLoss and Accuracy\n",
    "    )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    loop = training.Loop(TransformerLM(d_model=4,\n",
    "                                       d_ff=16,\n",
    "                                       n_layers=1,\n",
    "                                       n_heads=2,\n",
    "                                       mode='train'),\n",
    "                         train_task,\n",
    "                         eval_tasks=[eval_task],\n",
    "                         output_dir=output_dir)\n",
    "    \n",
    "    return loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1562,  1845,     8, 14607,  5318,    27, 22512,   494,     2,\n",
       "           964,     2,   864,  1976,  3873,  1248,   270,     6,  1054,\n",
       "          4410,   132,   213, 10995,   583,   527,    28, 18620,  2648,\n",
       "         18623,   157,  1353,   973,  1838, 10835,  3112,   102, 14850,\n",
       "            28,  8107,   132, 23677,     4,   527,   281,    32,   446,\n",
       "         20934,     4,     2,   213,  7802,   415, 20850,     7,     5,\n",
       "           676, 14380,   127,     3, 21338, 23450,     5,     2,  1570,\n",
       "             2,    28,   137,     6,   104,  7619,   527,   213, 22512,\n",
       "           494,  2713,   676,     2,   229,    43,  3873,  1248, 13961,\n",
       "          9236,  8970, 11599, 23297,   132,   213,   484,   583,   527,\n",
       "          5942,   821,     2,  1570,     3, 23450,     5,    80,   228,\n",
       "           186,  1078,  1689,   213,   281,   571,    88,   226,  1019,\n",
       "           213,  8107,    76,  1480,  2867,   229,   137,   237,   527,\n",
       "           213, 20934,     4,    76,   320,  4182,    15,  1186,  1838,\n",
       "         16994,     2,   127,  3306, 10323, 22991,    92,     2, 14380,\n",
       "          1019,   213,  7802,   415, 26319,     4,     3, 23450,     5,\n",
       "          1353,   973,  4901,   102, 23056,  3112,     2, 10323, 22991,\n",
       "            92,   127,  1133, 27634,     4,   567,   213,    55,    41,\n",
       "           124,   213, 12683,   126,   186,   539,   527,   285,   844,\n",
       "             2,   125,   450,   103,     7,     5,   285,   532,   132,\n",
       "           213,  1859,  4617, 27634,   391, 10323, 22991,    92,   793,\n",
       "         14607,     3,   821,    80,   779,     2,  9778,     2,  1874,\n",
       "             2,   527, 24482,  1907,     2,   964,     2,  3268,  4620,\n",
       "            17,   320, 23450,     5,    80,  1186,   186,   127, 23450,\n",
       "             5,   170,    18,    46,   475,   341, 20934,     4,  1133,\n",
       "         27634,     4,    13,   358,     7,    26,   483,   134,   973,\n",
       "           166,    22, 23181,   114, 13355,   130,   293,  4617, 27634,\n",
       "           391,   127,   821,     2,  1779,     7,     5,    28,  1646,\n",
       "         13035,  1019,   213,   986,   748,     3,    69,  1353,   163,\n",
       "          1127, 10696,    81,   132,   707, 16735,  1019,   137,    91,\n",
       "            29,    28, 12499,  2415,  2112,     2,    22,   169, 15192,\n",
       "           650,     6,   320,     6,   650,  5421,   320, 16272,   416,\n",
       "           320,  3573,   186,  5005,     2,    22,   127,     3,  1312,\n",
       "          3873,   132,   213,   821,   347,   229,  1497, 16169,     3,\n",
       "          7796,  3975,  3790, 15310, 19922,     2,  1779,   229,  3873,\n",
       "          1248, 13961,  9236,  8970, 11599, 23297,   186,  8284, 10990,\n",
       "           147,   527, 13241,  1017,     3,    69,  1353,   973,   220,\n",
       "           719,    78,   281,   393,    88,   226, 20934,     4,     3,\n",
       "          1775,  2021,    18, 18915,    17,    19,  8272,   320,   213,\n",
       "          3748,     3,     9,    72,   313,  1435,   398,   635, 22512,\n",
       "           494,   864,  2021,    76,    38,   313,    76,  1779,    25,\n",
       "           810,   132,   213,   821,  6901,   186,    18,    46,  1471,\n",
       "            78, 13961,  9236,  8970,     2,  1537,  3541,  1377,     3,\n",
       "             9, 13151,   229,    43, 14169,   213,  4287,  1019,  1424,\n",
       "           544, 10457,     3,  9778,   821,     2,   213,   779,     2,\n",
       "           127,  3112,    22,  2976,  2781,  3748,   214,   193,   527,\n",
       "           213,    54,   290,  2021,  1133, 27634,     4,  1473,   122,\n",
       "            22,   141,  4530,    77,   186,   206,  5778,  1290,     2,\n",
       "           285,     7,     5,  2754,    22,   170,  1151,  3873,  1248,\n",
       "             3,    69,   790,     7,    26,  2481,   130,   293,     7,\n",
       "             5,   583,  4617, 27634,   391,   821,   127,     3,     9,\n",
       "          7802,   415,   960,  7047,     7,     5,   797,   127,   824,\n",
       "           984,   285,    92,  3748,    25,  5159,   214,   213,    54,\n",
       "           290,   166,   669, 27634,     4,   213,   760,   302,    19,\n",
       "           344,  7084,  2676,   132,   163, 25528,  1258,    78,   213,\n",
       "           160,   527,    97,  2021,  4172, 27634,   391,  5942,   821,\n",
       "             2,    28,  1570,     6,   104,     6,   292, 18623,   157,\n",
       "          1248, 26738, 23529,    28,     2,  1353, 10996,   691,   864,\n",
       "           145,   163,  7877,  3191,   484,    65,   186,   710,   409,\n",
       "           390,   272,     3,     9,   347,  7121,  5512,  1236,   320,\n",
       "           213,   864,  2154,   527, 22512,   494,     2,  2685,   393,\n",
       "          1059, 11382,   527,  5702,  1562,  1845,     3,  1191,   146,\n",
       "             2,    72,    54, 11498,   527, 23181,   554,   809,   213,\n",
       "          1759,   527,   306,   864,    18,  9643, 25086,     2,   148,\n",
       "          1730, 12084,  1173, 20100,     5,   132,   387,     3,  1193,\n",
       "          8480,  4152, 10726,  3051, 14058,   412,   186,  2907, 13021,\n",
       "             5,  4924,   381,  1170,   527,  2137, 21849, 11519,   846,\n",
       "          2313,  2754,  2195,   132,   213,   821,   347,     2, 10726,\n",
       "          3051, 14058,   412,    23,   127,     3,   821,  4133,  2644,\n",
       "          6341,     2, 23028, 16204,     5,     2,  5150,     4, 16204,\n",
       "             5,     2,   186,  2333,  6483,  9249,   186, 12563,  7580,\n",
       "           400,     2,   213, 13021,     4,     7,     5,   797,   127,\n",
       "             3,     9,  7802,   415, 19853,    81,  1490,    15,  2324,\n",
       "           527,   583,   412,    28, 13638, 10970,   186,   127,    22,\n",
       "           710,   102,   523,    15, 16872, 26847,  1407,     2,  2252,\n",
       "           134,  3630,   320,  7884,    14,     3, 23450,     5,    40,\n",
       "           133,  1981,  1242,  1248,   821,    76,  1457,    22,  1669,\n",
       "           412,    28,   669, 27634,     4, 18623, 10607,    81, 27634,\n",
       "            76,   102,   864,   625,    28,   922,  2685,    28, 18623,\n",
       "           157,   996,   132,  1081,  3778,   186, 19277,    78, 20623,\n",
       "             5,   527, 19363,    17,  3040,     2, 10726,  3051, 14058,\n",
       "           412,   127,  1133, 27634,     4,    69, 18283,    15, 20490,\n",
       "             5,   320,  5942,   821,   186,    22,   127,   948,   267,\n",
       "           172,   130, 20490,     4,    98,  1333,    41,     7,   165,\n",
       "          1269,   320,  2127,   320,   242,    33,    61, 22137,   669,\n",
       "         27634,   391, 10726,  3051, 14058,   412,   127,     2,   354,\n",
       "           669, 27634,     4,   242, 27634,   391,  1382,   527,   213,\n",
       "           444,  7648,  4854,   360,     3,     9,   960,  7047,   127,\n",
       "         23450,     5,    80,  2751,  1353, 19357, 12965,   217,   186,\n",
       "           669, 27634,     4,    19,  9434,   186,  2554, 27634,   391,\n",
       "           213,   218,  1133, 27634,     4, 23450,     5,    40,   320,\n",
       "           288,   285,    22,  1353,  2167,    28,  1359,  4872,  5942,\n",
       "           821, 19042,  1019,    15,   177,   186,  1353, 10655,   320,\n",
       "           211,   463,  1838,   163,  4574,  1976,  1779,  1353,   416,\n",
       "           320,   117,   242,   134,    61, 22137, 27634,   391, 10726,\n",
       "          3051, 14058,   412,   127,     3,  3790, 15310, 19922,  2362,\n",
       "           809,   213,  1610,   272,     3,    69,   229,  5754,   527,\n",
       "           354, 13241,  1017,  7511,    22, 12365, 24810,    17,   186,\n",
       "          2530,   821,     2,   176,   354,   213,   979,   250,   527,\n",
       "            15, 11818,    81,   320,  1205,   213,  7599,    78,   213,\n",
       "           570,   186,   882,  1223,   450,   192,   213,   157,  1353,\n",
       "         13082,    17,   320,   213,   927,   691,    54,  2021,     3,\n",
       "           348,   285,   340,     2,   821,  1353,   454,    92, 21708,\n",
       "           478,  3949,     2,  7134,   285,    22,  1353,   669, 27634,\n",
       "             4,   246,   186,  5585,  5973,  4617, 27634,   391,   213,\n",
       "         13021,     4,     7,     5,   797,   127,     3, 14607,     7,\n",
       "             5, 25000,   551, 22951,  3625,   320,   824,   648,    10,\n",
       "             1,     0, 19088,    11,  5440,   527,  6402,  4410,  7599,\n",
       "          3520,   320,  1186,  1838, 10835, 16346, 27439,  6774,  1628,\n",
       "          2445,   186,  1078,   527,  3797, 21338, 23450,     5,   399,\n",
       "          3606,   750,   320,   440,   134, 16346, 27439,  6774,  1628,\n",
       "         23450,     5,   186,    15,  5478,  1153,   281,   571,    88,\n",
       "           226,  1019,    28,  8107,   132, 23677,     4,   527, 20934,\n",
       "             4, 16346, 27439,  6774,  1628,  1902,  1976,  3873,   132,\n",
       "         18623,   157,     7,     5,   583,   229,   440,    78,   281,\n",
       "           393,    88,   226, 20934,     4,  2104,     1]]),\n",
       " array([[ 1562,  1845,     8, 14607,  5318,    27, 22512,   494,     2,\n",
       "           964,     2,   864,  1976,  3873,  1248,   270,     6,  1054,\n",
       "          4410,   132,   213, 10995,   583,   527,    28, 18620,  2648,\n",
       "         18623,   157,  1353,   973,  1838, 10835,  3112,   102, 14850,\n",
       "            28,  8107,   132, 23677,     4,   527,   281,    32,   446,\n",
       "         20934,     4,     2,   213,  7802,   415, 20850,     7,     5,\n",
       "           676, 14380,   127,     3, 21338, 23450,     5,     2,  1570,\n",
       "             2,    28,   137,     6,   104,  7619,   527,   213, 22512,\n",
       "           494,  2713,   676,     2,   229,    43,  3873,  1248, 13961,\n",
       "          9236,  8970, 11599, 23297,   132,   213,   484,   583,   527,\n",
       "          5942,   821,     2,  1570,     3, 23450,     5,    80,   228,\n",
       "           186,  1078,  1689,   213,   281,   571,    88,   226,  1019,\n",
       "           213,  8107,    76,  1480,  2867,   229,   137,   237,   527,\n",
       "           213, 20934,     4,    76,   320,  4182,    15,  1186,  1838,\n",
       "         16994,     2,   127,  3306, 10323, 22991,    92,     2, 14380,\n",
       "          1019,   213,  7802,   415, 26319,     4,     3, 23450,     5,\n",
       "          1353,   973,  4901,   102, 23056,  3112,     2, 10323, 22991,\n",
       "            92,   127,  1133, 27634,     4,   567,   213,    55,    41,\n",
       "           124,   213, 12683,   126,   186,   539,   527,   285,   844,\n",
       "             2,   125,   450,   103,     7,     5,   285,   532,   132,\n",
       "           213,  1859,  4617, 27634,   391, 10323, 22991,    92,   793,\n",
       "         14607,     3,   821,    80,   779,     2,  9778,     2,  1874,\n",
       "             2,   527, 24482,  1907,     2,   964,     2,  3268,  4620,\n",
       "            17,   320, 23450,     5,    80,  1186,   186,   127, 23450,\n",
       "             5,   170,    18,    46,   475,   341, 20934,     4,  1133,\n",
       "         27634,     4,    13,   358,     7,    26,   483,   134,   973,\n",
       "           166,    22, 23181,   114, 13355,   130,   293,  4617, 27634,\n",
       "           391,   127,   821,     2,  1779,     7,     5,    28,  1646,\n",
       "         13035,  1019,   213,   986,   748,     3,    69,  1353,   163,\n",
       "          1127, 10696,    81,   132,   707, 16735,  1019,   137,    91,\n",
       "            29,    28, 12499,  2415,  2112,     2,    22,   169, 15192,\n",
       "           650,     6,   320,     6,   650,  5421,   320, 16272,   416,\n",
       "           320,  3573,   186,  5005,     2,    22,   127,     3,  1312,\n",
       "          3873,   132,   213,   821,   347,   229,  1497, 16169,     3,\n",
       "          7796,  3975,  3790, 15310, 19922,     2,  1779,   229,  3873,\n",
       "          1248, 13961,  9236,  8970, 11599, 23297,   186,  8284, 10990,\n",
       "           147,   527, 13241,  1017,     3,    69,  1353,   973,   220,\n",
       "           719,    78,   281,   393,    88,   226, 20934,     4,     3,\n",
       "          1775,  2021,    18, 18915,    17,    19,  8272,   320,   213,\n",
       "          3748,     3,     9,    72,   313,  1435,   398,   635, 22512,\n",
       "           494,   864,  2021,    76,    38,   313,    76,  1779,    25,\n",
       "           810,   132,   213,   821,  6901,   186,    18,    46,  1471,\n",
       "            78, 13961,  9236,  8970,     2,  1537,  3541,  1377,     3,\n",
       "             9, 13151,   229,    43, 14169,   213,  4287,  1019,  1424,\n",
       "           544, 10457,     3,  9778,   821,     2,   213,   779,     2,\n",
       "           127,  3112,    22,  2976,  2781,  3748,   214,   193,   527,\n",
       "           213,    54,   290,  2021,  1133, 27634,     4,  1473,   122,\n",
       "            22,   141,  4530,    77,   186,   206,  5778,  1290,     2,\n",
       "           285,     7,     5,  2754,    22,   170,  1151,  3873,  1248,\n",
       "             3,    69,   790,     7,    26,  2481,   130,   293,     7,\n",
       "             5,   583,  4617, 27634,   391,   821,   127,     3,     9,\n",
       "          7802,   415,   960,  7047,     7,     5,   797,   127,   824,\n",
       "           984,   285,    92,  3748,    25,  5159,   214,   213,    54,\n",
       "           290,   166,   669, 27634,     4,   213,   760,   302,    19,\n",
       "           344,  7084,  2676,   132,   163, 25528,  1258,    78,   213,\n",
       "           160,   527,    97,  2021,  4172, 27634,   391,  5942,   821,\n",
       "             2,    28,  1570,     6,   104,     6,   292, 18623,   157,\n",
       "          1248, 26738, 23529,    28,     2,  1353, 10996,   691,   864,\n",
       "           145,   163,  7877,  3191,   484,    65,   186,   710,   409,\n",
       "           390,   272,     3,     9,   347,  7121,  5512,  1236,   320,\n",
       "           213,   864,  2154,   527, 22512,   494,     2,  2685,   393,\n",
       "          1059, 11382,   527,  5702,  1562,  1845,     3,  1191,   146,\n",
       "             2,    72,    54, 11498,   527, 23181,   554,   809,   213,\n",
       "          1759,   527,   306,   864,    18,  9643, 25086,     2,   148,\n",
       "          1730, 12084,  1173, 20100,     5,   132,   387,     3,  1193,\n",
       "          8480,  4152, 10726,  3051, 14058,   412,   186,  2907, 13021,\n",
       "             5,  4924,   381,  1170,   527,  2137, 21849, 11519,   846,\n",
       "          2313,  2754,  2195,   132,   213,   821,   347,     2, 10726,\n",
       "          3051, 14058,   412,    23,   127,     3,   821,  4133,  2644,\n",
       "          6341,     2, 23028, 16204,     5,     2,  5150,     4, 16204,\n",
       "             5,     2,   186,  2333,  6483,  9249,   186, 12563,  7580,\n",
       "           400,     2,   213, 13021,     4,     7,     5,   797,   127,\n",
       "             3,     9,  7802,   415, 19853,    81,  1490,    15,  2324,\n",
       "           527,   583,   412,    28, 13638, 10970,   186,   127,    22,\n",
       "           710,   102,   523,    15, 16872, 26847,  1407,     2,  2252,\n",
       "           134,  3630,   320,  7884,    14,     3, 23450,     5,    40,\n",
       "           133,  1981,  1242,  1248,   821,    76,  1457,    22,  1669,\n",
       "           412,    28,   669, 27634,     4, 18623, 10607,    81, 27634,\n",
       "            76,   102,   864,   625,    28,   922,  2685,    28, 18623,\n",
       "           157,   996,   132,  1081,  3778,   186, 19277,    78, 20623,\n",
       "             5,   527, 19363,    17,  3040,     2, 10726,  3051, 14058,\n",
       "           412,   127,  1133, 27634,     4,    69, 18283,    15, 20490,\n",
       "             5,   320,  5942,   821,   186,    22,   127,   948,   267,\n",
       "           172,   130, 20490,     4,    98,  1333,    41,     7,   165,\n",
       "          1269,   320,  2127,   320,   242,    33,    61, 22137,   669,\n",
       "         27634,   391, 10726,  3051, 14058,   412,   127,     2,   354,\n",
       "           669, 27634,     4,   242, 27634,   391,  1382,   527,   213,\n",
       "           444,  7648,  4854,   360,     3,     9,   960,  7047,   127,\n",
       "         23450,     5,    80,  2751,  1353, 19357, 12965,   217,   186,\n",
       "           669, 27634,     4,    19,  9434,   186,  2554, 27634,   391,\n",
       "           213,   218,  1133, 27634,     4, 23450,     5,    40,   320,\n",
       "           288,   285,    22,  1353,  2167,    28,  1359,  4872,  5942,\n",
       "           821, 19042,  1019,    15,   177,   186,  1353, 10655,   320,\n",
       "           211,   463,  1838,   163,  4574,  1976,  1779,  1353,   416,\n",
       "           320,   117,   242,   134,    61, 22137, 27634,   391, 10726,\n",
       "          3051, 14058,   412,   127,     3,  3790, 15310, 19922,  2362,\n",
       "           809,   213,  1610,   272,     3,    69,   229,  5754,   527,\n",
       "           354, 13241,  1017,  7511,    22, 12365, 24810,    17,   186,\n",
       "          2530,   821,     2,   176,   354,   213,   979,   250,   527,\n",
       "            15, 11818,    81,   320,  1205,   213,  7599,    78,   213,\n",
       "           570,   186,   882,  1223,   450,   192,   213,   157,  1353,\n",
       "         13082,    17,   320,   213,   927,   691,    54,  2021,     3,\n",
       "           348,   285,   340,     2,   821,  1353,   454,    92, 21708,\n",
       "           478,  3949,     2,  7134,   285,    22,  1353,   669, 27634,\n",
       "             4,   246,   186,  5585,  5973,  4617, 27634,   391,   213,\n",
       "         13021,     4,     7,     5,   797,   127,     3, 14607,     7,\n",
       "             5, 25000,   551, 22951,  3625,   320,   824,   648,    10,\n",
       "             1,     0, 19088,    11,  5440,   527,  6402,  4410,  7599,\n",
       "          3520,   320,  1186,  1838, 10835, 16346, 27439,  6774,  1628,\n",
       "          2445,   186,  1078,   527,  3797, 21338, 23450,     5,   399,\n",
       "          3606,   750,   320,   440,   134, 16346, 27439,  6774,  1628,\n",
       "         23450,     5,   186,    15,  5478,  1153,   281,   571,    88,\n",
       "           226,  1019,    28,  8107,   132, 23677,     4,   527, 20934,\n",
       "             4, 16346, 27439,  6774,  1628,  1902,  1976,  3873,   132,\n",
       "         18623,   157,     7,     5,   583,   229,   440,    78,   281,\n",
       "           393,    88,   226, 20934,     4,  2104,     1]]),\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=train_batch_stream\n",
    "next(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"By . Daily Mail Reporter . PUBLISHED: . 20:59 EST, 10 December 2012 .\\n| . UPDATED: . 19:21 EST, 11 December 2012 . A petrol-bomb attack on a\\npolicewoman was yesterday being treated as attempted murder. A gang of\\naround 15 men surrounded the unmarked car as the officer sat inside,\\nsmashed its windows and threw in the bomb. Following the incident, the\\nworst in more than a week of disorder in Belfast, the Northern Ireland\\nSecretary attacked Loyalist mobs for ‘dishonouring and shaming’ the\\nUnion Flag. A police patrol car sits burnt outside Alliance Party MP\\nNaomi Long's office in east Belfast, Northern Ireland after being\\nattacked by a masked gang of men with a petrol bomb . A forensic\\nofficer works around a burnt out the unmarked police car. About 15\\nmasked men smashed the windows of the police car and threw a petrol\\nbomb into it while an officer was still inside, police said . An\\nunmarked police car was also paint bombed . MPs united to condemn the\\noutbreak of . violence, which began after the number of days the\\nBritish flag flies . above Belfast City Hall was cut. The woman\\nofficer was guarding the . Belfast offices of Alliance Party MP Naomi\\nLong, who had received a . death threat after her cross-community\\nparty backed the controversial . move to reduce the number of days on\\nwhich the flag was flown. The woman officer escaped unhurt but . the\\nattack, on Monday, was one of several incidents across the province .\\nwhich police said were being ‘stoked’ by social media. Yesterday\\nTheresa Villiers told MPs: . ‘There is nothing remotely British about\\nwhat they are doing; they are . dishonouring and shaming the flag of\\nour country with their lawless and . violent activities.' Thirty-two\\npolice officers have been hurt and 38 people charged since the\\nviolence began. Rioters gathered at Broadway Roundabout following a\\nprotest over the decision by Belfast City Council to stop flying the\\nunion flag every day . PSNI Assistant Chief Constable George .\\nHamilton said the officer was lucky to escape with his life outside\\nthe . MP's office on the Newtownards Road. Officers were also attacked\\nwith petrol bombs in south Belfast close to the M1 motorway. He .\\nsaid: 'This was a planned attempt to kill a police officer which also\\n. put the lives of the public in danger and it is fortunate there were\\nno . injuries.' Peter Robinson, . the Northern Ireland First Minister\\nand leader of the Democratic . Unionist Party had talks in Belfast\\nwith Mike Nesbitt, leader of . the Ulster Unionist Party to try to\\nagree some sort of agreed political . strategy in a bid to ease\\ntensions and end the violence on the streets. They . have been heavily\\ncriticised by nationalist representatives over their . leadership\\nsince the trouble first flared a week ago. The trouble followed a\\ncouncil decision to limit the flying of the Union flag to designated\\ndays only. Ms Long's Alliance Party has been blamed by the loyalists\\nfor supporting the nationalist SDLP and Sinn Fein in pushing through\\nthe vote to lower the flag. There were also protests\\xa0 in Limavady, Co\\nLondonderry, Ballyclare, Co Antrim, Ballycastle, Co Antrim and\\nCookstown, Co Tyrone where the car of a DUP member of the Northern\\nIreland Assembly, Ian McCrea, was surrounded by loyalist who were\\nangry at his presence. Several roads in Belfast were blocked and at\\none stage police were also attacked with petrol bombs and fireworks at\\nBroadway, not far from the M1 motorway. Last week Ms Long was told by\\npolice to stay away from her home and her office on the Newtownards\\nRoad because of fears for her safety. Constituency offices used by the\\nparty were also attacked in Carrickfergus, Co Antrim and Bangor, Co\\nDown. Mr Robinson and Mr Nesbitt have already called for loyalist\\nrestraint, and according to a statement tonight they agreed to work on\\na 'joint basis with a view to urgently bringing forward political\\nproposals to address widespread concerns across the\\ncommunity.'<EOS><pad>Gangof men tossed petrol bomb in unmarked vehicle\\n. It was parked close to offices of Alliance Party MP Naomi Long .\\nComes after decision by Belfast City Council to restrict the flying of\\nthe union flag .<EOS><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad\\n><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad\\n><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad\\n><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad\\n><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad\\n><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad\\n><pad><pad><pad>\",\n",
       " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article,summary,mask=next(b)\n",
    "detokenize(article[0]),mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the model will be trained for only 10 steps. \n",
    "\n",
    "Even with this constraint the model with the original default arguments took a very long time to finish. Because of this some parameters are changed when defining the model that is fed into the training loop in the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "BFRBTwSqRWRZ",
    "outputId": "aff859e5-8f4a-4d3b-f1d3-98e137581a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step      1: Ran 1 train steps in 9.42 secs\n",
      "Step      1: train CrossEntropyLoss |  10.41214275\n",
      "Step      1: eval  CrossEntropyLoss |  10.41417313\n",
      "Step      1: eval          Accuracy |  0.00000000\n",
      "\n",
      "Step     10: Ran 9 train steps in 64.87 secs\n",
      "Step     10: train CrossEntropyLoss |  10.41274357\n",
      "Step     10: eval  CrossEntropyLoss |  10.41328049\n",
      "Step     10: eval          Accuracy |  0.00000000\n"
     ]
    }
   ],
   "source": [
    "# Should take around 1.5 minutes\n",
    "!rm -f ~/model/model.pkl.gz\n",
    "loop = training_loop(TransformerLM, train_batch_stream, eval_batch_stream)\n",
    "loop.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XKrEBjmskeWa"
   },
   "source": [
    " <a name='4'></a>\n",
    " # Part 4:  Evaluation  \n",
    "\n",
    "<a name='4.1'></a>\n",
    "### 4.1 Loading in a trained model\n",
    "\n",
    "In this part you will evaluate by loading in an almost exact version of the model you coded, but we trained it for you to save you time. Please run the cell below to load in the model.\n",
    "\n",
    "As you may have already noticed the model that you trained and the pretrained model share the same overall architecture but they have different values for some of the parameters:\n",
    "\n",
    "    \n",
    "   `Original (pretrained) model: `                                 \n",
    "                                       \n",
    "    TransformerLM(vocab_size=33300, d_model=512, d_ff=2048, n_layers=6, n_heads=8, \n",
    "                   dropout=0.1, max_len=4096, ff_activation=tl.Relu)\n",
    "                   \n",
    "   `Your model:`\n",
    "   \n",
    "    TransformerLM(d_model=4, d_ff=16, n_layers=1, n_heads=2)\n",
    "   \n",
    "   **Only the parameters shown for your model were changed. The others stayed the same.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "zWoSzR5tkoAx",
    "outputId": "2b9f1cca-4778-4509-bd9e-bd1738625a4e"
   },
   "outputs": [],
   "source": [
    "# Get the model architecture\n",
    "model = TransformerLM(mode='eval')\n",
    "\n",
    "# Load the pre-trained weights\n",
    "model.init_from_file('model.pkl.gz', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Serial[\n",
       "  ShiftRight(1)\n",
       "  Embedding_33300_512\n",
       "  Dropout\n",
       "  PositionalEncoding\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Serial[\n",
       "          Branch_out3[\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "          ]\n",
       "          DotProductAttn_in3\n",
       "          AttnOutput\n",
       "          Dense_512\n",
       "        ]\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Dense_2048\n",
       "        Relu\n",
       "        Dropout\n",
       "        Dense_512\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Serial[\n",
       "          Branch_out3[\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "          ]\n",
       "          DotProductAttn_in3\n",
       "          AttnOutput\n",
       "          Dense_512\n",
       "        ]\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Dense_2048\n",
       "        Relu\n",
       "        Dropout\n",
       "        Dense_512\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Serial[\n",
       "          Branch_out3[\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "          ]\n",
       "          DotProductAttn_in3\n",
       "          AttnOutput\n",
       "          Dense_512\n",
       "        ]\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Dense_2048\n",
       "        Relu\n",
       "        Dropout\n",
       "        Dense_512\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Serial[\n",
       "          Branch_out3[\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "          ]\n",
       "          DotProductAttn_in3\n",
       "          AttnOutput\n",
       "          Dense_512\n",
       "        ]\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Dense_2048\n",
       "        Relu\n",
       "        Dropout\n",
       "        Dense_512\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Serial[\n",
       "          Branch_out3[\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "          ]\n",
       "          DotProductAttn_in3\n",
       "          AttnOutput\n",
       "          Dense_512\n",
       "        ]\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Dense_2048\n",
       "        Relu\n",
       "        Dropout\n",
       "        Dense_512\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Serial[\n",
       "          Branch_out3[\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "            [Dense_512, AttnHeads]\n",
       "          ]\n",
       "          DotProductAttn_in3\n",
       "          AttnOutput\n",
       "          Dense_512\n",
       "        ]\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  Serial[\n",
       "    Branch_out2[\n",
       "      None\n",
       "      Serial[\n",
       "        LayerNorm\n",
       "        Dense_2048\n",
       "        Relu\n",
       "        Dropout\n",
       "        Dense_512\n",
       "        Dropout\n",
       "      ]\n",
       "    ]\n",
       "    Add_in2\n",
       "  ]\n",
       "  LayerNorm\n",
       "  Dense_33300\n",
       "  LogSoftmax\n",
       "]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilM9C8P3RWRf"
   },
   "source": [
    "<a name='5'></a>\n",
    "# Part 5: Testing with your own input\n",
    "\n",
    "You will now test your input. You are going to implement greedy decoding. This consists of two functions. The first one allows you to identify the next symbol. It gets the argmax of the output of your model and then returns that index. \n",
    "\n",
    "<a name='ex06'></a>\n",
    "### Exercise 06\n",
    "**Instructions:** Implement the next symbol function that takes in the cur_output_tokens and the trained model to return the index of the next word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rD_bXRCpRWRg"
   },
   "outputs": [],
   "source": [
    "# UNQ_C9\n",
    "def next_symbol(cur_output_tokens, model):\n",
    "    \"\"\"Returns the next symbol for a given sentence.\n",
    "\n",
    "    Args:\n",
    "        cur_output_tokens (list): tokenized sentence with EOS and PAD tokens at the end.\n",
    "        model (trax.layers.combinators.Serial): The transformer model.\n",
    "\n",
    "    Returns:\n",
    "        int: tokenized symbol.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    # current output tokens length\n",
    "    \n",
    "    token_length = len(cur_output_tokens)\n",
    "    # calculate the minimum power of 2 big enough to store token_length\n",
    "    # HINT: use np.ceil() and np.log2()\n",
    "    # add 1 to token_length so np.log2() doesn't receive 0 when token_length is 0\n",
    "    padded_length =2**int(np.ceil(np.log2(token_length + 1)))\n",
    "\n",
    "    # Fill cur_output_tokens with 0's until it reaches padded_length\n",
    "    padded =cur_output_tokens + [0] * (padded_length - token_length)\n",
    "   \n",
    "    padded_with_batch = np.array(padded)[None, :] # Don't replace this 'None'! This is a way of setting the batch dim\n",
    "    \n",
    "    # model expects a tuple containing two padded tensors (with batch)\n",
    "    output, _ =  model((padded_with_batch, padded_with_batch))\n",
    "    # HINT: output has shape (1, padded_length, vocab_size)\n",
    "    # To get log_probs you need to index output with 0 in the first dim\n",
    "    # token_length in the second dim and all of the entries for the last dim.\n",
    "    log_probs = output[0, token_length, :]\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return int(np.argmax(log_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 456, 483, 320, 4219, 132, 213, 2775, 10, 1, 0]\n",
      "[13, 456, 483, 320, 4219, 132, 213, 2775, 10, 1, 0, 0, 0, 0, 0, 0]\n",
      "[[  13  456  483  320 4219  132  213 2775   10    1    0    0    0    0\n",
      "     0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test it out!\n",
    "sentence_test_nxt_symbl = \"I really want to fly in the sky.\"\n",
    "detokenize([next_symbol(tokenize(sentence_test_nxt_symbl)+[0], model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "'The'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AwrQFglRWRj"
   },
   "source": [
    "<a name='5.1'></a>\n",
    "### 5.1 Greedy decoding\n",
    "\n",
    "Now you will implement the greedy_decode algorithm that will call the `next_symbol` function. It takes in the input_sentence, the trained model and returns the decoded sentence. \n",
    "\n",
    "<a name='ex07'></a>\n",
    "### Exercise 07\n",
    "\n",
    "**Instructions**: Implement the greedy_decode algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HwIdimiN0k2"
   },
   "outputs": [],
   "source": [
    "# UNQ_C10\n",
    "# Decoding functions.\n",
    "def greedy_decode(input_sentence, model):\n",
    "    \"\"\"Greedy decode function.\n",
    "\n",
    "    Args:\n",
    "        input_sentence (string): a sentence or article.\n",
    "        model (trax.layers.combinators.Serial): Transformer model.\n",
    "\n",
    "    Returns:\n",
    "        string: summary of the input.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # Use tokenize()\n",
    "    cur_output_tokens = tokenize(input_sentence) + [0]\n",
    "    generated_output = [] \n",
    "    cur_output = 0 \n",
    "    EOS = 1 \n",
    "    \n",
    "    while cur_output != EOS:\n",
    "        # Get next symbol\n",
    "        cur_output = next_symbol(cur_output_tokens, model)\n",
    "        # Append next symbol to original sentence\n",
    "        cur_output_tokens.append(cur_output)\n",
    "        # Append next symbol to generated sentence\n",
    "        generated_output.append(cur_output)\n",
    "        print(detokenize(generated_output))\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return detokenize(generated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "news='A 22-year-old Olympic surfing hopeful from El Salvador has died while training for an upcoming qualifying competition, the country surfing federation (FESASURF) has confirmed.Katherine Diaz was in the water at El Tunco beach in southwest El Salvador on Friday when she was struck by lightning, FESASURF told CNN. Katherine was a girl very passionate about sports, she was very motivated and happy for the event that was approaching,it said in a statement. The Paddle Out -- a ceremony in her honor -- will be held next Tuesday. El Salvador National Institute for Sport (INDES) said: We raise a prayer for the eternal rest of her soul and we express our most sincere condolences to her family.Katherine came over to hug her [friend], as soon as she finished hugging her, the noise was heard, Diasz uncle, Beto Diaz, who says he was in the water with her, told a newspaper in El Salvador. She, the friend, was thrown by the force of the lightning strike too, the board threw me back. Katherine died instantly. The International Surfing Association (ISA) 2021 Surf City El Salvador World Surfing Games are set to be held from May 29 to June 6 at the La Bocana and El Sunzal beaches and will act as the final qualifying tournament for Tokyo 2020, where surfing will be making its debut Olympic appearance.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "9kHuIDGW1sOr",
    "outputId": "2525ca2c-4625-47c0-8456-f75598581993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 22-year-old Olympic surfing hopeful from El Salvador has died while\n",
      "training for an upcoming qualifying competition, the country surfing\n",
      "federation (FESASURF) has confirmed.Katherine Diaz was in the water at\n",
      "El Tunco beach in southwest El Salvador on Friday when she was struck\n",
      "by lightning, FESASURF told CNN. Katherine was a girl very passionate\n",
      "about sports, she was very motivated and happy for the event that was\n",
      "approaching,it said in a statement. The Paddle Out -- a ceremony in\n",
      "her honor -- will be held next Tuesday. El Salvador National Institute\n",
      "for Sport (INDES) said: We raise a prayer for the eternal rest of her\n",
      "soul and we express our most sincere condolences to her\n",
      "family.Katherine came over to hug her [friend], as soon as she\n",
      "finished hugging her, the noise was heard, Diasz uncle, Beto Diaz, who\n",
      "says he was in the water with her, told a newspaper in El Salvador.\n",
      "She, the friend, was thrown by the force of the lightning strike too,\n",
      "the board threw me back. Katherine died instantly. The International\n",
      "Surfing Association (ISA) 2021 Surf City El Salvador World Surfing\n",
      "Games are set to be held from May 29 to June 6 at the La Bocana and El\n",
      "Sunzal beaches and will act as the final qualifying tournament for\n",
      "Tokyo 2020, where surfing will be making its debut Olympic appearance. \n",
      "\n",
      "El\n",
      "El Salva\n",
      "El Salvador\n",
      "El Salvador'\n",
      "El Salvador's\n",
      "El Salvador's surf\n",
      "El Salvador's surfing\n",
      "El Salvador's surfing federation\n",
      "El Salvador's surfing federation\n",
      "El Salvador's surfing federation confirms\n",
      "El Salvador's surfing federation confirms.\n",
      "El Salvador's surfing federation confirms. Katherine\n",
      "El Salvador's surfing federation confirms. Katherine Dia\n",
      "El Salvador's surfing federation confirms. Katherine Diaz\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salva\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador.\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by light\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning,\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "light\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning.\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salva\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CS\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES)\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES) is\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES) is being\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES) is being\n",
      "held\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES) is being\n",
      "held in\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES) is being\n",
      "held in El\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES) is being\n",
      "held in El Salva\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES) is being\n",
      "held in El Salvador\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES) is being\n",
      "held in El Salvador.\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES) is being\n",
      "held in El Salvador.<EOS>\n",
      "El Salvador's surfing federation confirms. Katherine Diaz was in the\n",
      "water at El Salvador. She was struck by lightning, but was struck by\n",
      "lightning. El Salvador National Institute for Sport (CSES) is being\n",
      "held in El Salvador.<EOS>\n"
     ]
    }
   ],
   "source": [
    "# Test it out on a sentence!\n",
    "test_sentence = \"It was a sunny day when I went to the market to buy some flowers. But I only found roses, not tulips.\"\n",
    "print(wrapper.fill(news), '\\n')\n",
    "print(greedy_decode(news, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CA-279WI2D3G"
   },
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    ":\n",
    ": I\n",
    ": I just\n",
    ": I just found\n",
    ": I just found ros\n",
    ": I just found roses\n",
    ": I just found roses,\n",
    ": I just found roses, not\n",
    ": I just found roses, not tu\n",
    ": I just found roses, not tulips\n",
    ": I just found roses, not tulips\n",
    ": I just found roses, not tulips.\n",
    ": I just found roses, not tulips.<EOS>\n",
    ": I just found roses, not tulips.<EOS>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DYgX-mzjyUia",
    "outputId": "b901e164-48b3-4124-d21a-fe7443d15b79"
   },
   "outputs": [],
   "source": [
    "# Test it out with a whole article!\n",
    "article = \"It’s the posing craze sweeping the U.S. after being brought to fame by skier Lindsey Vonn, soccer star Omar Cummings, baseball player Albert Pujols - and even Republican politician Rick Perry. But now four students at Riverhead High School on Long Island, New York, have been suspended for dropping to a knee and taking up a prayer pose to mimic Denver Broncos quarterback Tim Tebow. Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were all suspended for one day because the ‘Tebowing’ craze was blocking the hallway and presenting a safety hazard to students. Scroll down for video. Banned: Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll (all pictured left) were all suspended for one day by Riverhead High School on Long Island, New York, for their tribute to Broncos quarterback Tim Tebow. Issue: Four of the pupils were suspended for one day because they allegedly did not heed to warnings that the 'Tebowing' craze at the school was blocking the hallway and presenting a safety hazard to students.\"\n",
    "print(wrapper.fill(article), '\\n')\n",
    "print(greedy_decode(article, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "Jordan\n",
    "Jordan Ful\n",
    "Jordan Fulcol\n",
    "Jordan Fulcoly\n",
    "Jordan Fulcoly,\n",
    "Jordan Fulcoly, Wayne\n",
    "Jordan Fulcoly, Wayne Dre\n",
    "Jordan Fulcoly, Wayne Drexe\n",
    "Jordan Fulcoly, Wayne Drexel\n",
    "Jordan Fulcoly, Wayne Drexel,\n",
    ".\n",
    ".\n",
    ".\n",
    "\n",
    "Final summary:\n",
    "\n",
    "Jordan Fulcoly, Wayne Drexel, Tyler Carroll and Connor Carroll were\n",
    "suspended for one day. Four students were suspended for one day\n",
    "because they allegedly did not heed to warnings that the 'Tebowing'\n",
    "craze was blocking the hallway and presenting a safety hazard to\n",
    "students.<EOS>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing this week's assignment!** You did a lot of work and now you should have a better understanding of the encoder part of Transformers and how Transformers can be used for text summarization.\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "NLPC4-2"
   ]
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
